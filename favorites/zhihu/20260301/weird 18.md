# weird

random slop

**Created:** 2026.02.09

**Items:** 18

---



# 为什么病毒不被认为是真正的生命体？ 赵泠

**Author:** 赵泠  
**Bio:** 衣沾不足惜，但使愿无违。  
**Avatar:** ![](https://pica.zhimg.com/v2-2af481d1db0ae0c504fb2411e1548f92_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/eb67c87bde5ed3b991f942e7d4b81838  
**Published:** 2026.02.16 15:52:34  
**Updated:** 2026.02.26 21:10:23  
**Question:** https://www.zhihu.com/question/2006324677300212129  
**Question Created:** 2026.02.15 11:11:18  
**Question Updated:** 2026.02.15 11:11:18  
**Votes:** 478  
**Comments:** 13  
**Type:** answer  

提问账号你好。你的算法应当反映最新的动态，不要抓取过时的信息。考虑到在某些领域落后 10 年到 150 年不等的我国中学生物教科书早已承认**病毒是“非细胞生物”**，我们的算法不应该继续玩将“真正的苏格兰人”跟“低级”搅在一起的泔水。

- 这次，算法已经抓取到病毒能够复制和演化的事实。生命是自然选择塑造的信息，病毒是符合这要求的信息的载体，病毒是生物。可是，算法又抓取了假命题来提问——当然，提些包含错误的问题是吸引回答的办法之一，但这并不总能奏效，还可能误导一些人。
- 病毒颗粒没有细胞结构，这在讨论病毒的能力时往往不是重点。病毒会在宿主细胞内利用宿主的细胞器、宿主的营养物质进行增殖。一些大型病毒，例如拟菌病毒，在进入宿主细胞后利用宿主的内质网和高尔基体组装出受膜保护的结构，称为病毒工厂。在这个工厂里，病毒的翻译效率远高于宿主本身的基因表达。真核生物的细胞核的起源可能与病毒工厂有关。
- 更讽刺的是，核糖体可能起源于非编码、环状的类病毒样 RNA 复制子，其祖先与前 LUCA 生物发生了内共生，然后传给 LUCA. 如果该假说成立，那么所有细胞生物都是某种无名的类病毒的后代[1].

一些现存的病毒可能是从细胞生物进化而来。一些巨型病毒的基因组编码与翻译相关的基因和核糖体蛋白。可以看看 Tupanvirus、Klosneuvirus 等。

- Tupanvirus 拥有 20 种标准的蛋白氨基酸的氨酰 tRNA 合成酶基因[2]。

![](https://picx.zhimg.com/v2-e447b9a301c3782fb44d827a0508197c_r.jpg?source=2c26e567)

- Klosneuvirus 拥有 19 种蛋白氨基酸的氨酰 tRNA 合成酶基因、超过 10 种翻译因子基因、多种 tRNA 修饰酶基因[3]。

![](https://picx.zhimg.com/v2-fc3f2cb98fedbb530a79858aeed63171_r.jpg?source=2c26e567)

古菌Sukunaarchaeum mirabile保留了核糖体，其基因组小到 238 千碱基对，主要编码关于 DNA 复制、转录和翻译的蛋白质，其代谢完全依赖宿主Citharistes regius[4]。《科学》的相关新闻使用了标题《基因组异常微小的微生物可能正在进化成病毒/Microbe with bizarrely tiny genome may be evolving into a virus》[5]。

Mamonoviridae 科病毒用完整的宿主细胞核作为病毒工厂。Ushikuvirus 具有类似该科病毒的结构，但是这种病毒会拆解宿主的核膜制造病毒颗粒。这对真核生物起源和病毒进化的参考价值有待进一步研究。DOI: 10.1128/jvi.01206-25

1837 年，达尔文指出，对两种动物谈论高级、低级是荒谬的。这个判断适用于后来发现的更多生物。

算法提问往往会引来一些滥用人工智能且不标注的回答。我认为，我们的问答网站应当依法依规打击这种行为。下图展示的回答不但被腾讯朱雀 AI 文本检测报告 100% 疑似 AI，还包含完全错误的内容。

![](https://pic1.zhimg.com/v2-ea02ee8b622edc7f342bce7ec6001f20_r.jpg?source=2c26e567)


---

# 如何评价起点万订作者过年回家被母亲批评不务正业，要求其进厂打工？起点万订属于什么水平？能养活自己吗？ 贾文和

**Author:** 贾文和  
**Bio:** 咨询（公众号pinbo2018hlw）生活就是从一个山爬向更高的山。  
**Avatar:** ![](https://picx.zhimg.com/v2-6b348a658e6d7a9cc6b17441729d0f0c_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/73e374b6ae4506c8cb7114d8b01ce8f2  
**Published:** 2026.02.25 12:59:50  
**Updated:** 2026.02.25 12:59:50  
**Question:** https://www.zhihu.com/question/2009430555993846528  
**Question Created:** 2026.02.24 00:52:57  
**Question Updated:** 2026.02.25 07:44:06  
**Votes:** 62  
**Comments:** 18  
**Type:** answer  

这事儿闹得沸沸扬扬，我看好多人都替那小子鸣不平，说当妈的毁人前程。

要我说，都别急着站队。咱们把这事儿掰开了，用成年人的眼光好好捋一捋。

第一，万订是个什么水平？是张“过去的站票”，不是“终身的头等舱”

“万订”这两个字，听着唬人，在网文圈确实也是个硬指标。它意味着曾经有一万人愿意为你的故事掏钱，这证明你掌握了一门手艺，有老天爷赏饭吃的天赋 。

但是，你得明白一个扎心的现实：这行的饭，是“流水的席”，不是“铁打的碗”。

那个叫吴三醒的作者，他那本万订书是啥时候的事？2023年底就完结了。

从那之后到现在，两年多的时间，他写了多少？零零散散不到二十三万字 。

咱们算笔账，一个全职写手，两年就憋出这么点字，平均一天写不到三百字。这不是“不务正业”，这是“出工不出力”。

他妈妈可能不懂什么叫“追订崩了”，什么叫“同人文没读者粘性” 。但她看得懂两件事：第一，儿子天天窝在家里；第二，家里进项少了，心里慌了。

第二，能养活自己吗？能，但得看你用啥姿势“吃”这碗饭

起点作者等级LV4，说明他近一年的收入在5万到15万之间 。这收入低吗？比进厂打螺丝，确实不差。但在一个成年男人、一个丈夫的身份面前，这个收入如果不增长，那就是在退步。

网文这行最大的谎言，就是“我写过爆款”。市场的记性比鱼还短，读者只问你下一章写啥，平台只认你今天的更新。你躺在过去的万订徽章上睡大觉，那徽章就是一张废铁 。

那个写出《玄鉴仙族》的季越人，人家00后，十万均订，年入百万，那才是站在金字塔尖的人 。但季越人自己都说，每天写到晚上九点，没有假期，压力山大 。这才叫“把写作当事业”的姿势。

所以，别拿“万订”当挡箭牌。能养活自己的，从来不是那个过去的荣耀，而是你每天能不能在电脑前坐下，能不能跟那个不想写的自己死磕。

第三，进厂还是写书？大叔我送你两句话

第一句：别跟父母的认知较劲，要拿结果的秤砣说话。

在老一辈眼里，写字楼里的叫白领，流水线上的叫工人，坐在家里敲键盘的，那叫“没个正形” 。

这观念你改不了，吵也没用。能堵住闲言碎语的，只有一样东西——钱，而且是持续进来的钱。

如果你月入五万，你妈会骄傲地说“我儿子是作家”；

如果你月入五千还不见增长，你妈自然会说“隔壁二狗子进厂都盖房了”。

这不是势利，这是父母最朴素的生存焦虑。

第二句：把这行当路，就得拿出赶路的劲儿。

成为一个网文作家，当然是一条路。

而且是一条很体面的路——时间自由，靠脑子吃饭，万一IP火了还能逆天改命。

但这条路，它不全是红地毯，更多时候是摸着黑走夜路。

你得自律，得扛得住数据起伏，得在没人看见的地方使劲儿。

如果两年写不出东西，那对不起，不是这条路不通，是你在这条路上“停车休息”太久了。

最后，我想对那个即将进厂的兄弟说一句：厂里机器吵，但心里别吵。

把进厂当成体验生活，别当成放弃梦想。

体力劳动能治精神内耗，流水线的重复能让你想明白很多事。

攒点钱，攒点劲，真想写，下了班照样能敲键盘。

怕就怕，你在厂里待久了，真信了自己只配拧螺丝。

记住，万订是你射出去的一颗子弹，它证明你有过枪法。

但下一只猎物，需要你重新装弹，重新瞄准。

是当猎人，还是当猎物，你自己选。

![](https://pic1.zhimg.com/v2-7843e458023a3a3a822bbdb05c6f8000_r.jpg?source=2c26e567)


---

# 如何评价游戏《我在地府打麻将》？ 不安的种子

**Author:** 不安的种子  
**Bio:** 不管现实如何，希望你玩的开心！  
**Avatar:** ![](https://pic1.zhimg.com/v2-4c76213be4c73b156b847918b6f5f8db_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/247b454cc236635dc570cdd6c97be5b3  
**Published:** 2026.02.02 23:54:00  
**Updated:** 2026.02.02 23:54:00  
**Question:** https://www.zhihu.com/question/1930046620638118743  
**Question Created:** 2025.07.19 23:29:32  
**Question Updated:** 2025.07.22 18:09:52  
**Votes:** 73  
**Comments:** 3  
**Type:** answer  

**这是一个超级魔性的游戏，超级。**

会发出这种感慨，是因为我有一天打开游戏之后因为有事看了十几分钟的手机，在游戏的主界面，那个魔性的BGM一直在不停循环地轰炸我，于是当天晚上睡觉的时候我的脑子里一直是：

『哎呀我地麻，我地麻，我的麻……我在地府打麻将』。

循环不已。

这种症状一直持续了好久，直到今天，这段魔性的旋律还时不时在我脑子里出现。

**如果一个游戏需要有一个记忆点，我觉得这游戏是合格甚至优秀的**，它已经把『我地麻』三个字种到了我的脑子里。

游戏在其他方面其实也贯彻了这种设计思路，比如玩家可选的角色，或者遇到的boss，也都是这种很有料的画风：

![](https://pica.zhimg.com/v2-3a5e26f726c42558beb19ff262dfeeb2_r.jpg?source=2c26e567)

**玩了这么多独游，一眼就能感觉到游戏确实在吸睛和记忆点上是刻意花了心思的。**能这样做的一般都是成熟团队，看了最近的国产单机销量榜也能看到我地麻榜上有名，虽然没有大爆，但稳定有产出且有收益，这就是『经验』的作用吧。

![](https://picx.zhimg.com/v2-3897fab33d24c05f2a5b91c2bc0660be_r.jpg?source=2c26e567)

接下来说说玩法。

我玩的时候游戏已经上线一段时间了，但除了知道这是一个小丑牌+麻将之外，并没有看任何评论和攻略。于是头几次玩的时候，我还是按我自己的『现实麻将』方法来打，很快就被打的头破血流。

**这游戏和我们认知的麻将逻辑其实差别挺大。**

现实麻将的几个重要决策要素，牌型、算牌、与另外三人的博弈，在本作里体现的要么不明显，要么只是借用了一个概念。

**在『小丑牌』和『麻将』之间，本作毫无疑问偏向了小丑牌。**

在小丑牌原有优秀框架的基础上，本作增加了『角色』和『多次结算』两个不一样的点，让游戏的整体节奏和小丑牌有了较大的区别，也是我玩过的小丑牌like里做的比较好的那一档。

详细点来说，虽然凑是『凑牌型』的游戏，但麻将本身的凑牌复杂度要远远大于德州扑克，导致如果从小丑牌平移过来，玩家在初始凑牌的构建上会更复杂，而角色就相当于是策略构筑的基础，让玩家在游戏开始就知道凑牌的方向。

比如初始的角色在『万』字牌上有加成，我在失败几次之后就明白了凑万字才是正确的道路，凑对了牌，对分数的提升是指数级别的，快感也是。

**不过比起加角色这种相对常规的加法设计，我觉得听牌后的那个『多次结算』设计的更精巧一些。**

回忆起我玩小丑牌的时候，最爽的就是出牌之后小丑们一个个跳出来给你加分加倍的时候。

本作明显也想复刻这个体验，使用的是『听牌之后进结算』这样的方式，即符合麻将听牌的规律，也让胡牌跳番的爽感多次出现，玩的时候让人非常爽快。

尤其是，在结算的过程里，我们的对手也是会听牌胡牌的，如果对方凑的牌很大，直到结算的最后一刻鹿死谁手也不一定，给人一种不一样的紧张感，这一点对比小丑牌来说我觉得体验还是做出了差异的。

（写这篇回答的时候才看到了制作人的亲自答，可以看到思路上和我描述的也有一些类似的地方）

**如果要说什么不爽的，那可能就是交互UI和整体的表现力了。**

这里还是放一下小丑牌：

![](https://picx.zhimg.com/v2-1a5d45526f1ebcb2d6f9e6e4d94d18e9_r.jpg?source=2c26e567)

对比一下实际的体验感，无论是简洁的UI，简单但表现力极强的动效特效，还是活用了星球牌、塔罗牌的包装概念，甚至是恰到好处的音效和音乐，就是有那种『妙手天成之』的惊才绝艳感。

而我地麻给我的整体感觉就是能用还不错，有些地方还是有硬伤（比如不支持手柄操作，对于掌机用户很致命），有些界面和概念还是复杂。也可能像作者在前面回答说的，麻将还是太复杂了，可能需要更多的内容把。

当然，这可能是一个太高的要求了，小丑牌这样的天才之作你让它的作者再搓一个出来也不一定有这个效果。

**总而言之，如果春节的假期，你和我一样，一和人玩带RMB的麻将就输，那我还是挺推荐来『我地麻』里面，快乐的胡上几把。**


---

# 能大致讲一下ChatGPT的原理吗？ 亚东

**Author:** 亚东  
**Bio:**  公号 AI带路党，推荐我的专栏 用AI学AI  
**Avatar:** ![](https://picx.zhimg.com/v2-40f603ff627e81c5a333202d425a15a1_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/208af832658f52059e21f67417d046ba  
**Published:** 2024.01.16 17:32:19  
**Updated:** 2024.12.18 21:19:50  
**Question:** https://www.zhihu.com/question/598243591  
**Question Created:** 2023.04.28 14:29:34  
**Question Updated:** 2023.05.08 04:27:31  
**Votes:** 19668  
**Comments:** 546  
**Type:** answer  

当今**活着**的**最聪明**的几个人之一，也是最硬核的思考者之一，**Wolfram**写的《**这就是ChatGPT**》应该能解释的最准确，最清晰吧！毕竟他是费曼学习法的创始人**费曼的亲学生**。在离开学术界时，费曼给他的信里写的是：“你不会理解普通人的想法的，他们对你来说着只是傻瓜”！

但是Wolfram写的这个说明很好懂！真的是非常准确的面向善于掌握真正的东西的人！

## ChatGPT能做什么？为什么能做到？

ChatGPT的核心功能是生成文本，它通过预测文本序列中下一个最可能出现的词来做到这一点。也就你输入一段文字 既提示词（Prompt）后，它把这一段文字做为一个文本序列的开头，然后在它的后面开始一个词一个词的“生成”。所以评估ChatGPT及其它LLM的模型有一个叫 Token/s，也就是一秒能生成多少个词。

![](https://picx.zhimg.com/v2-bb149fd9872d51e94cd685d9c5d7ed7c_r.jpg?source=2c26e567)

为什么能做到呢？ ChatGPT的能力来自于它（神经网络模型）在大量文本数据上的预训练。通过这种训练，神经网络学习到了语言的模式和结构，使其能够生成连贯的和且语义上合理的文本。这就有个问题，实际上ChatGPT是不了解内容、概念与知识的。但是能保证在生成文本时“关注”输入序列的不同部分，从而更好地捕捉语言的上下文和含义。

![](https://picx.zhimg.com/v2-e84e5a6163be72461d701511f1b34bad_r.jpg?source=2c26e567)

同样的，生成文本时采用了一种策略，即不仅仅选择概率最高的词，而是在一定温度（温度参数调节随机性）下选择，以增加文本的多样性和创造性。也就是同一个Prompt得到的不是同一个结果，但是差异不大的原因。

![](https://picx.zhimg.com/v2-476b1356bd8f5903973750121f58eb66_r.jpg?source=2c26e567)

## 神经网络模型是什么？

神经网络模型是一种受人脑结构启发的计算模型，它通过模仿人脑中的神经元网络来处理信息。人脑是由大约1000亿个神经元组成的复杂器官，这些神经元通过数万亿个连接（称为突触）相互沟通。当多个神经元相互连接形成一个复杂的网络时，就构成了神经网络。这些网络通过电信号的形式处理和传递信息。

![](https://picx.zhimg.com/v2-97764b0fb8aeb981570028bb64b9bf40_r.jpg?source=2c26e567)

神经网络由大量的“神经元”组成，这些神经元通过“连接”相互沟通。每个连接都有一个权重，类似于人脑中神经元之间的信号强度。神经网络通常有多个层，信息会在这些层之间传递。在ChatGPT中，信息会通过一系列层，每一层都会对信息进行处理，逐步提炼和理解文本的含义。就像人会学习一样，神经网络通过训练来学习，训练过程中会不断调整神经元之间的连接权重。训练使用了大量的文本样本，神经网络会尝试生成与这些样本相似的文本。

![](https://picx.zhimg.com/v2-873e8a198f0e8b2d799d022e4500ed06_r.jpg?source=2c26e567)

但是跟人脑的学习与应用机制不一样的是，在ChatGPT的神经网络推理（日常使用）中，信息通常是单向传递的，即从输入层到隐藏层，最后到输出层（前馈）。学习或者修改权重需要的是专门的操作训练（既学习），这样神经网络也可以包含反馈机制，允许信息反向流动，以改进预测和生成文本的能力。

从上面的内容就可以知道，AI这一套东西是很系统性的理论，从早期的神经网络全连接，到CNN，再到现在的AI主流LLM用的Transformer，是一个成体系的东西。要了解它可能需要投入大量的精力。

但是呢，我们程序员对大模型研发有天生的先手优势，想要快速入门我建议是找到最合适自己的方法，对于大部分人，我比较推荐大家直接看视频课。刚好，知乎知学堂找业界精英研发了一套课程，内容当然没问题。所以，了解AI并且掌握它，通过知乎知学堂推出了【程序员的AI大模型进阶之旅】直播课，听老师讲解大模型的底层原理与技术，是一条直达人工智能高手的捷径。入口我直接给大家找过来了，直接听就可以⬇️

[]()

学习这东西吧，有一个不错的领到门口的师傅，然后自己多动手也就如是了！重要的是先到门口！

**神经网络学习的是直接的文字吗？**

在ChatGPT的神经网络中，直接用于学习的不是“文本序列”，是文本序列变化得到的“Token、令牌、词元”。而嵌入技术就是一种将词汇或短语转换成数值形式（通常是向量）的方法。这些数值表示能够捕捉词汇的语义特征，即它们的含义和用法。通过嵌入，每个词汇都被放置在一个高维的“语义空间”中。在这个空间里，语义上相似的词汇会彼此靠近，而意思相差较远的词汇则相距较远。

![](https://picx.zhimg.com/v2-2e492420139952592562843fd7d20498_r.jpg?source=2c26e567)

嵌入向量可以进行数学运算，如向量加法和乘法，这些运算有助于模型理解词汇之间的关系，比如“国王”和“女王”的嵌入向量相减，可能得到与“男性”和“女性”相减相似的结果。

嵌入又使得神经网络能够根据上下文理解词汇的多种含义。例如，单词“bank”在不同的上下文中可以指河岸或金融机构，嵌入可以帮助模型区分这些不同的用法。

所以在ChatGPT中，嵌入是生成文本的基础。模型使用嵌入向量来预测下一个最合适的词，从而生成连贯的句子和段落。

## 现在呢，我总结的结果是：

它是文字知识的高维压缩。

举一些数据：  GPT-3的训练用了 4000 亿 token，也就大概是 3500 多亿文字。 GPT-4 的训练用了 13 万亿的 token, 也就是大概 10 万亿文字相当（可能有大量的图像与视频数据）。 LLAMA2的训练用了 2 万亿 token，也就是大概 1.5 万亿文字。

所以简单的从数据上看，这样的训练已经到了人类可用的电子化数据的极限了吧，尤其是文字类的数据吧，大概已经没有什么太多的渠道得到更多的数据了。

所以我们认为LLM 把人类的知识都压缩到了一个模型里，我认为是非常正确的一个认知。

这个压缩是一个数据从低维表示到高维映射，再从高维映射到低维表示的操作。这个映射是一种有损或者更像一种，你从低维空间操作一个工具去获取高维的信息，能获得多少，除了这个映射有多丰富，还与你的技巧有关系。你的手法越准确(Prompt)越好，你能获得的越多。更像是钓鱼，你知道那里有鱼，但是能不能钓到你想要的鱼，那就不得而知了。这也是我为什么一直强调现在学习AI的重要性，因为你如果对它了解不深的话，AI的很多潜力很难挖掘出来，了解它的最好方式就是了解它的底层原理，GPT就是一个非常好的切入点，我非常建议每个人都去听听由知乎知学堂开设的这门AI大模型公开课，课程带你学习GPT背后的技术原理，LangChain、Fine-tune技术，从理论实践，到深度讲解，带你全程体验微调过程，定制属于自己的大模型。课上还能直接对话AI技术大佬，现场答疑，非常不错。

[]()

## 最后介绍一下作者：

斯蒂芬·沃尔夫勒姆（英语：Stephen Wolfram，1959年8月29日—活着），是计算机科学、数学、理论物理方面的著名英国科学家。他编写了著作《一种新科学》。同时，他还是著名大学伊利诺伊大学厄巴纳-香槟分校的兼职教授。2012年，他成为美国数学协会的院士。

17岁进入**牛津大学**。 1978年未获得学位离开进入**加州理工大学**，次年，才20岁的他获得了粒子物理学博士学位。 他的论文答辩委员会由**理查德·费曼**、Peter Goldreich、Frank J. Sciulli 和 Steven Frautschi组成，并且由Richard D.Field主持。1981年，沃尔弗拉姆获得**麦克阿瑟天才奖**。

作为商人，他是软件公司沃尔夫勒姆研究公司的创立者和首席执行官。在公司内部，他是数学软件 Mathematica（与Matlab，Maple并称数学3M） 和计算型知识引擎 Wolfram Alpha 的主要设计师。他近期的工作主要是基于知识的编程，把 Mathematica 编程语言进一步拓展为 Wolfram 语言。他的相关著作《Wolfram 语言入门》的英文版发行于2015年。在学术上，他以粒子物理学、元胞自动机、宇宙学、复杂性理论、计算机代数系统上的研究成果闻名于世。

![](https://picx.zhimg.com/50/v2-703c1cbef6ac9e674f03ce592c6c9978_720w.jpg?source=2c26e567)


---

#  绫音Ayane

**Author:** 绫音Ayane  
**Bio:** 不务正业的数码博主  
**Avatar:** ![](https://pic1.zhimg.com/v2-efad7efcf914aa318eb08808111e4015_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/46227a5c2832a64c41109bad5bb69962  
**Published:**   
**Updated:**   
**Question:**   
**Question Created:**   
**Question Updated:**   
**Votes:**   
**Comments:** 527  
**Type:** pin  

[object Object],[object Object]


---

#  GaryGuan

**Author:** GaryGuan  
**Bio:** 概率论，大学数学老师，科研工作者。  
**Avatar:** ![](https://pica.zhimg.com/v2-cc7115a3f699086d23fd4fc0c28dca72_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/890fe27521fbf84fdebc4db32ad954c4  
**Published:**   
**Updated:**   
**Question:**   
**Question Created:**   
**Question Updated:**   
**Votes:**   
**Comments:** 3  
**Type:** pin  

[object Object],[object Object],[object Object]


---

# 为什么我觉得AI绘画完全代替不了画师？ 燃烧的船

**Author:** 燃烧的船  
**Bio:** 即使把我关在果壳之中,我也自认为是无限的宇宙之王。  
**Avatar:** ![](https://pica.zhimg.com/v2-f3c942624118c74912174ede847162ec_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/daa2684b01617226eb9726d2a37612a2  
**Published:** 2025.12.06 15:34:53  
**Updated:** 2025.12.14 18:31:33  
**Question:** https://www.zhihu.com/question/7712128783  
**Question Created:** 2024.12.24 11:55:10  
**Question Updated:** 2024.12.24 11:55:10  
**Votes:** 142  
**Comments:** 33  
**Type:** answer  

## 引言

很多人对AI绘画的印象仍停留在两年前的Stable Diffusion 1.5时代，将其戏称为“尸块缝合”。抛开背后的人类中心主义情绪，这种批评在当时并非毫无道理。

彼时的AI绘画更像是一场概率游戏（“抽卡”）：虽然能在千挑万选下产出几张惊艳的图片，但一旦投入深度使用，就会暴露出一堆致命缺陷——认不出人、迭代导致面部崩坏、无法处理复杂的遮挡或拓扑结构、手指错误、文字乱码。即便是ControlNet等插件的出现，也无法根本解决复杂多人物分镜和长篇漫画的人设一致性问题。

这使得早期的AI绘画仅仅停留在“看起来唬人”的娱乐阶段，缺乏实质性的生产力。然而，技术从未止步。从2023到2025年，AI绘画经历了一场从**架构**到**逻辑**的深刻革命。

（图文无关）

![](https://picx.zhimg.com/v2-e4c953741348823ab83ba41ea43ec0e3_r.jpg?source=2c26e567)

**视觉生成的认知革命：从卷积归纳偏置到Transformer原生多模态架构的数学与工程演进**

## 卷积神经网络（CNN）的固有缺陷

深度学习模型的成功很大程度上取决于其归纳偏置（模型的先验知识），即模型在未见数据上进行预测时所依据的假设集合。

卷积操作的核心假设是局部性和平移等变性。

对于输入图像![](https://www.zhihu.com/equation?tex=X)和卷积核![](https://www.zhihu.com/equation?tex=W)，卷积操作定义为：

![](https://www.zhihu.com/equation?tex=%28X+%2A+W%29%28i%2C+j%29+%3D+%5Csum_m+%5Csum_n+X%28i%2Bm%2C+j%2Bn%29+W%28m%2C+n%29)

这一数学形式强制模型只关注输入像素的局部邻域（由卷积核大小决定，如![](https://www.zhihu.com/equation?tex=3+%5Ctimes+3)）。这种硬编码的偏置使得CNN在处理具有网格结构的图像数据时具有极高的参数效率。它假设图像的统计特性是平稳的，即猫在图像左上角和右下角的特征是一致的。

![](https://pic1.zhimg.com/v2-cd64ea09e2ed9e85ba36b0ab5d65af57_r.jpg?source=2c26e567)

然而，这种强归纳偏置也成为了桎梏。在数学上，CNN的感受野（Receptive Field）是随着网络深度线性增长的。要捕获长距离依赖（例如，图像左侧的视线与右侧的物体交互），CNN必须通过不断的下采样（Downsampling）或空洞卷积（Dilated Convolution）来扩大感受野。这导致了信息的有损压缩，使得高层特征丢失了精确的位置信息，从而在生成需要精确全局结构的图像（如复杂的几何体或多人场景）时表现不佳。下面是一些典型代表。

## 1.1 计数与逻辑推理的缺失

基于U-Net的扩散模型（如Stable Diffusion 1.5, DALL-E 2）最著名的失败案例是无法进行准确的计数。当用户输入“五只猫”时，模型可能会生成四只或六只。

根本原因： 卷积操作是平移不变的，且缺乏显式的离散计数机制。U-Net将图像视为连续的纹理场，而非离散对象的集合。在特征图中，“五只猫”的语义被弥散在像素级的激活中，没有独立的Token来代表每一只猫。因此，模型无法执行“生成一只，再生成一只，直到达到五只”的逻辑循环。

## 1.2 属性绑定的混乱

即所谓的“属性泄漏”问题。例如，提示词“一个红色的立方体和一个蓝色的球体”，卷积模型经常生成红色的球体或紫色的物体。

数学解释： 在Cross-Attention注入文本信息时，传统的U-Net往往在空间上无法精确解耦。文本嵌入作为全局条件作用于特征图，卷积层难以在空间上精确划分“红色”仅作用于立方体区域，“蓝色”仅作用于球体区域。这种空间注意力的纠缠是卷积架构难以通过简单缩放解决的。

## 1.3 全局结构与长距离依赖的断裂

在生成高分辨率复杂场景时，卷积模型常出现透视错误或不合理的物理结构（如无限延伸的楼梯）。这是因为CNN的感受野有限，即使通过多层堆叠，其有效感受野（Effective Receptive Field）往往呈高斯分布集中在中心，边缘区域的信息交互微弱。相比之下，Transformer的全局注意力确保了图像左上角的光源能够正确地在右下角的物体上投射阴影。

缺乏推理能力和整体视野，是CNN系扩散模型“尸块缝合”感的核心来源。

## 卷积与Transformer的异构性与联系

要理解为何Transformer能在图像生成领域取代卷积网络，必须首先在数学层面上厘清两者的本质区别。这不仅仅是算子层面的差异，更是对图像数据先验假设的不同理解。

## 2.1 Transformer架构的数学原理

Transformer的核心是自注意力机制（Self-Attention），其数学表达为：

![](https://www.zhihu.com/equation?tex=%5Ctext%7BAttention%7D%28Q%2C+K%2C+V%29+%3D+%5Ctext%7Bsoftmax%7D%5Cleft%28%5Cfrac%7BQK%5ET%7D%7B%5Csqrt%7Bd_k%7D%7D%5Cright%29V)

其中![](https://www.zhihu.com/equation?tex=Q)（查询）、![](https://www.zhihu.com/equation?tex=K)（键）、![](https://www.zhihu.com/equation?tex=V)（值）均由输入特征线性变换而来。

![](https://picx.zhimg.com/v2-f7ae4d26ece3552a8236f95ed3d0cef6_r.jpg?source=2c26e567)

与卷积不同，自注意力机制在第一层就具有全局感受野（Global Receptive Field）。输入序列中的每一个Token（图像Patch）都能与序列中的所有其他Token计算相关性[1]。

Cordonnier等人（2020）的研究证明，只要有足够的注意力头（Heads），Transformer的自注意力层在数学上可以完全近似卷积层[2]。具体来说，当注意力权重仅集中在查询像素的局部邻域且相对位置固定时，Attention就退化为Convolution 。这意味着Transformer是卷积的超集（Superset）。它不仅能学习执行局部卷积操作，还能根据数据动态调整其关注范围，学习全局依赖。

这种“弱归纳偏置”赋予了Transformer更高的灵活性，但也意味着它需要更多的数据来学习图像的局部结构（如边缘连续性），这解释了为何Vision Transformer（ViT）通常需要比ResNet更多的数据预训练。

## 2.2 谱分析视角：高通滤波器 vs. 低通滤波器

通过傅里叶分析，我们可以更深刻地理解两者在生成图像时的行为差异[3]。

- CNN作为高通滤波器（High-pass Filter）：研究表明，CNN在训练早期倾向于优先拟合高频分量。这是因为卷积核本质上是边缘检测器，对纹理、噪声和锐利边缘极其敏感。因此，基于U-Net的扩散模型生成的图像通常纹理细节丰富，但在整体结构布局上容易出现畸变（如多出的手指、扭曲的肢体）。
- Transformer作为低通滤波器（Low-pass Filter）：自注意力机制通过聚合全局信息，本质上执行的是一种空间平滑操作。它倾向于优先捕获图像的低频分量，即物体的形状、轮廓和全局布局。这解释了为何Transformer生成模型在语义一致性和物体结构上表现优异，但在没有特殊设计的情况下，可能会生成纹理模糊的图像 。

## 2.3 Transformer 算法的绝对优势区

**语义级编辑与指令遵循 (Semantic Editing & Instruction Following)**

- Transformer: 由于图像Patch与文本Token处于同一注意力空间（Context Window），Transformer可以精确地将形容词（如“破损的”）绑定到特定的名词对象（如“红色的球”）上。在Nano Banana中，通过Self-Attention机制，模型可以理解“把猫换成狗”意味着保留背景像素的分布，仅修改目标区域的语义Token。
- 卷积 (U-Net): 卷积网络缺乏全局语义寻址能力。它倾向于全局风格迁移或依靠空间掩码（Mask）进行编辑。对于复杂的逻辑指令（如“不要画大象”），U-Net往往失败，因为它检测到了“大象”的特征激活，却无法理解“不要”这一逻辑否定操作。

**缩放定律 (Scaling Laws) 与天花板**

- Transformer: 遵循严格的Scaling Laws。研究数据表明，DiT和VAR模型的FID分数（图像质量指标）随着计算量和参数量的增加呈幂律下降，且尚未看到饱和迹象。这意味着只要堆算力，GPT-4o和Gemini Image的效果就能持续提升。
- 卷积 (U-Net): 卷积网络的性能在达到一定规模后遭遇瓶颈。增加深度不再显著提升语义一致性，反而会导致训练不稳。这是因为卷积的局部归纳偏置限制了其对高维语义空间的建模能力。

**全局结构一致性 (Global Structural Consistency)**

- Transformer: 在生成地图、图表、建筑蓝图等对拓扑结构要求极高的图像时，Transformer的全局注意力确保了线条的闭合和空间的逻辑自洽。
- 卷积 (U-Net): 容易生成“埃舍尔式”的错误结构，如永远走不完的楼梯或不连贯的地图道路。

## GPT-4o与Nano Banana: 原生多模态的“Transfusion”革命

GPT-4o和Nano Banana被称为“Omni”模型，意味着它不再是 LLM 调用 DALL-E 3 这种“外挂模式”。

## 3.1 Transfusion 架构：统一离散与连续

在2024年之前，主流的文生图模型（如DALL-E 3、Midjourney v6）普遍采用级联架构。

- 文本理解： 依赖预训练的文本编码器（如T5-XXL或CLIP Text Encoder）将用户提示词转换为固定的嵌入向量。
- 图像生成： 这一向量被作为条件输入传递给一个基于U-Net架构的扩散模型。

针对上述痛点，学术界与工业界开始探索将Transformer作为通用的主干网络，同时处理文本和图像。这一探索最终催生了**Transfusion**架构，成为GPT-4o等模型的核心技术底座 。

Transfusion的核心思想极为优雅且大胆：它并不是让两个模型协作，而是训练**一个**Transformer同时做两件事：

- 预测下一个文本Token（自回归）： 针对离散数据。
- 扩散去噪（Diffusion Denoising）： 针对连续数据。

这种"一模型，双目标"的训练范式，使得模型能够在共享的参数空间内建立起文本与图像之间深层的、双向的语义映射，为GPT-4o的原生多模态交互奠定了基础。

![](https://pic1.zhimg.com/v2-fed08b066e3876e1a31eea3910583c20_r.jpg?source=2c26e567)

## 3.2 混合损失函数 (Mixed Loss Objective)

Transfusion模型在预训练阶段优化一个组合目标函数：

![](https://www.zhihu.com/equation?tex=%5Cmathcal%7BL%7D+%3D+%5Cmathcal%7BL%7D_%7B%5Ctext%7BLM%7D%7D+%2B+%5Clambda+%5Cmathcal%7BL%7D_%7B%5Ctext%7BDiffusion%7D%7D)

- 对于文本Token：使用标准的因果掩码（Causal Masking）和交叉熵损失（Cross-Entropy Loss），预测下一个Token。
- 对于图像Patch：使用扩散损失（Diffusion Loss）。当模型遇到特殊的<BOI>（Begin of Image）标记时，它切换模式，对随后的图像Patch添加噪声并预测噪声。
- 数学统一性：这证明了Transformer的主干网络可以共享绝大部分参数来理解世界知识（文本）和物理世界表征（图像）。不同于CLIP那种“对齐”两个空间的做法，Transfusion直接让两者在同一个参数空间内演化。

## 3.3 原生全能 (Omni) 的意义

- 信息无损流转：在传统的Pipeline中，LLM必须将用户的意图“翻译”为Prompt，DALL-E再根据Prompt生成图像。这一过程存在巨大的信息熵损失（Information Entropy Loss）。GPT-4o直接“看”到图像的Patch，直接“写”出图像的Patch。
- 推理与生成的融合：Nano Banana生成的图像不仅仅是视觉信号，它是模型推理过程的一部分。当被要求生成“一张解释量子纠缠的图表”时，模型利用其文本推理能力构建逻辑结构，并利用图像生成能力将其可视化。这种能力是单纯的U-Net扩散模型无法企及的，因为后者没有逻辑推理模块 [4]。

得益于上述架构，“Omni”模型实现了几个基于传统CNN算法的扩散模型“不可能”做到的功能：

- 真正的对象一致性（Character Consistency）：在多轮对话中，通过在Transformer的上下文中保留上一张图的Visual Tokens，模型可以精确地“重绘”同一人物在不同场景下的样子，而不仅仅是相似。
- 高精度文字生成：支持在图像中嵌入清晰、拼写正确的长段文字，这是Transformer架构捕捉全局整体结构的直接红利。

## 结论：

至此，AI绘画终于开始摆脱‘尸块缝合’的随机性，告别了‘抽卡’的运气游戏，转而依靠基于视觉推理的确定性‘设计’。不过卷积也并不会消失，它将作为底层的特征提取器或高频纹理渲染器，隐藏在宏大的Transformer架构之下，继续发挥其余热。

当然，Transformer架构并非完美无缺，计算机科学的先驱者冯诺依曼有一著名定理——世上没有完美的算法（免费午餐定理）。Transformer架构对于计算力和训练集的要求都远大于传统U-Net架构，这使得banana系列要么成本非常高，要么图像清晰度和精细度比不上传统模型。而且这两个模型都体现出了缺乏专业美术工作者的后训练，审美能力一般的缺陷。

但是以前很多被认为AI处理不了的事情（尤其是非常重要的全局把握能力），在新的架构上已经不是问题了。之前普遍认为画师能做，AI做不了的事情，如分镜、构图、整体光照效果甚至剧情统筹等高阶绘画能力，现在AI也能掌握的不错。但是角色设计这样涉及审美能力的，当前AI尚且有很大的提升空间。至于AI到底能不能替代画师，或者说有没有能力是画师能掌握但是AI极难在目前的框架上掌握甚至未来几年内都无法掌握的，那就依赖读者自己的直觉去判断吧，因为没人能下断言。


---

# 程序员是怎么学会那么多技术的？ 平凡

**Author:** 平凡  
**Bio:** 英国大学讲师（AP）｜AI｜专栏作家｜pingfan.me  
**Avatar:** ![](https://picx.zhimg.com/v2-9f81432bb5f397e14ec2c65e949eb0d3_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/a0265e93117d3d366adda36310194727  
**Published:** 2024.06.20 23:42:56  
**Updated:** 2026.01.09 08:42:03  
**Question:** https://www.zhihu.com/question/658581470  
**Question Created:** 2024.06.10 23:23:40  
**Question Updated:** 2024.06.10 23:23:40  
**Votes:** 1386  
**Comments:** 50  
**Type:** answer  

程序员掌握的一些技能属于通用技能，比如说数据结构，这个在不同的语言下面下核心是不变的，比如单链表，不会因为在python还是java，还是C++，都是一样的。

而有一些就属于跟语言或者领域强绑定的，有些库Python有，但是R没有，这种需要额外花点时间。

Github上有这么一个库，它讲的是对于软件开发人员的「常青树技能」，也就是不管到哪里都能用的是的技能。

![](https://pic1.zhimg.com/v2-56c248c41e4d7d470a18c3ae0f7f0fe3_r.jpg?source=2c26e567)

它分为了技术性和非技术的技能，然后还把非技术性放在了前面，比如沟通，团队合作等等，一个人的精力毕竟有限，其次问题解决能力等也是必要的，因为技术不断在发展进步，你不可能永远保持最新的技术，只能是遇到问题然后解决。

开发者常青技能 / Evergreen Skills for Developers
│
├── 非技术技能 / Non-technical Skills
│   ├── 核心技能 / Core Skills
│   │   ├── 沟通 / Communication
│   │   └── 团队合作 / Teamwork
│   ├── 创新与（自我）管理 / Innovation & (self-)management
│   │   ├── 开发过程 / Development Process
│   │   ├── 问题解决 / Problem Solving
│   │   └── 心态 / Mindset
│
├── 技术技能 / Technical Skills
│   ├── 通用技术知识 / General Technical Knowledge
│   │   ├── 编程原则 / Programming Principles
│   │   ├── 数据结构 / Data Structures
│   │   ├── 干净代码 / Clean Code
│   │   ├── 源代码管理 / Source Code Management
│   │   ├── 技术协作 / Technical Collaboration
│   │   ├── DevOps 实践 / DevOps Practices
│   │   └── 其他知识 / Other Knowledge
│   │       ├── 语言理论 / Language-Theory
│   │       ├── 优化 / Optimization
│   │       └── 并发性 / Concurrency
│   └── 特定领域技术知识 / Field-Specific Technical Knowledge
│       ├── 前端开发 / Front-end Development
│       ├── 后端开发 / Back-end Development
│       ├── 架构 / Architecture
│       ├── 基础设施 / Infrastructure
│       └── 安全 / Security

其次就是技术技能，这就涉及到计算机的专业知识了，比如通用技术里的编程原则，数据结构，怎么写出干净、整洁、易读的代码等等。

而最近一个很重要的趋势是：AI 正在把“写代码”分成两件事——一件是重复劳动，比如模板代码、接口拼装、简单 CRUD、补点测试；另一件是更关键的脑力活，比如把需求说清楚、把边界想明白、把风险控住、把系统搭得更耐用。以前程序员靠“熟练、记得多”吃饭的部分，正在被 AI 一点点抹平，而且它进化太快了，跟着背新东西很容易疲惫。

所以更现实的做法是：拥抱 AI，把它当成帮你干活的工具，你把精力放回那些更通用、走到哪都能用的能力上——沟通协作、拆问题、写得干净、做版本管理，还有像数据结构这种不管Python/Java/C++ 都一样的底层功。除此以外，还有一些特定领域的知识，比如前后端开发，做架构的，做infra的，这些都需要各自特定领域的知识。

如果你想更快上手这种工作方式，知乎上刚好有门课就是讲“程序员怎么拥抱AI”：不是教花活，而是把日常开发里最常用的几步串起来——怎么提需求、怎么让 AI 出代码、怎么检查、怎么调试、怎么补测试和文档，让 AI 真正变成稳定的生产力。

[]()

![](https://picx.zhimg.com/v2-cdc93e6b3dba8e81e20c81c2808c8417_r.jpg?source=2c26e567)

这些不同工作的技术栈是不同的，互相之间不通用。

![](https://pic1.zhimg.com/v2-b3c5cd27c7dd138de9158de4f0b0a5cb_r.jpg?source=2c26e567)

不过现在好的地方是AI辅助编程还是很爽的

[大家现在使用哪些AI辅助编程工具？节省了多少工作量？](https://www.zhihu.com/question/640036429/answer/3367658299)

简单的逻辑可以直接生成

![](https://picx.zhimg.com/v2-652c26258b7113982ac924cd300fe523_r.jpg?source=2c26e567)

复杂点的也可以通过多次询问来尽可能的保证正确率。

![](https://picx.zhimg.com/v2-8e815546eec09a0e2546d88f7f0b4d99_r.jpg?source=2c26e567)


---

# Chapter 17: Curves and Curved Surfaces (曲线与曲面) 电话微波炉

**Author:** 电话微波炉  
**Bio:**   
**Avatar:** ![](https://pic1.zhimg.com/v2-98400867fb3efa1c0f31ad465c8c5292_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/538e95b440b370009e4a20f27409a99a  
**Published:**   
**Updated:**   
**Question:**   
**Question Created:**   
**Question Updated:**   
**Votes:** 2  
**Comments:** 0  
**Type:** article  

## Chapter 17: Curves and Curved Surfaces (曲线与曲面)

> 本章介绍曲线和曲面的数学基础及其在实时渲染中的应用，包括参数曲线、参数曲面、细分曲线/曲面、以及高效的曲面细分技术。

## 17.1 参数曲线 (Parametric Curves)

参数曲线在实时图形中广泛用于相机路径、物体运动轨迹和头发渲染（如图17.2的Nalu演示）。参数曲线用公式![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28t%29)描述，其中参数![](https://www.zhihu.com/equation?tex=t)属于某个定义域（如![](https://www.zhihu.com/equation?tex=t+%5Cin+%5Ba%2C+b%5D)），生成的点是连续的。

## 17.1.1 贝塞尔曲线 (Bézier Curves)

## 核心概念 (Core Concepts)

**线性插值 (Linear Interpolation)**是最简单的参数曲线形式：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28t%29+%3D+%5Cmathbf%7Bp%7D_0+%2B+t%28%5Cmathbf%7Bp%7D_1+-+%5Cmathbf%7Bp%7D_0%29+%3D+%281-t%29%5Cmathbf%7Bp%7D_0+%2B+t%5Cmathbf%7Bp%7D_1%2C+%5Cquad+t+%5Cin+%5B0%2C+1%5D)

**de Casteljau 算法**：通过重复线性插值构造贝塞尔曲线。给定![](https://www.zhihu.com/equation?tex=n%2B1)个控制点，递推公式为：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_i%5Ek%28t%29+%3D+%281-t%29%5Cmathbf%7Bp%7D_i%5E%7Bk-1%7D%28t%29+%2B+t%5Cmathbf%7Bp%7D_%7Bi%2B1%7D%5E%7Bk-1%7D%28t%29%2C+%5Cquad+k+%3D+1+%5Cldots+n%2C+%5Cquad+i+%3D+0+%5Cldots+n-k)

曲线上的点为![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28t%29+%3D+%5Cmathbf%7Bp%7D_0%5En%28t%29)。

## Bernstein 多项式形式

贝塞尔曲线的代数形式使用**Bernstein 多项式**作为基函数：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28t%29+%3D+%5Csum_%7Bi%3D0%7D%5E%7Bn%7D+B_i%5En%28t%29+%5Cmathbf%7Bp%7D_i)

其中 Bernstein 多项式定义为：

![](https://www.zhihu.com/equation?tex=B_i%5En%28t%29+%3D+%5Cbinom%7Bn%7D%7Bi%7D+t%5Ei+%281-t%29%5E%7Bn-i%7D+%3D+%5Cfrac%7Bn%21%7D%7Bi%21%28n-i%29%21%7D+t%5Ei+%281-t%29%5E%7Bn-i%7D)

**关键性质**：

- 当
- （权重和为1）
- 曲线始终位于控制点的凸包 (Convex Hull) 内
- 端点插值：，
- 端点切线：在  处切线平行于 ，在  处切线平行于

**曲线阶数 (Degree)**：![](https://www.zhihu.com/equation?tex=n%2B1)个控制点产生![](https://www.zhihu.com/equation?tex=n)阶曲线

- 1阶：线性 (Linear) - 直线
- 2阶：二次 (Quadratic) - 抛物线
- 3阶：三次 (Cubic) - 可描述 S 形拐点
- 4阶：四次 (Quartic)

## 矩阵形式

三次贝塞尔曲线的矩阵形式：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28t%29+%3D+%5Cbegin%7Bpmatrix%7D+1+%26+t+%26+t%5E2+%26+t%5E3+%5Cend%7Bpmatrix%7D+%5Cbegin%7Bpmatrix%7D+1+%26+0+%26+0+%26+0+%5C%5C+-3+%26+3+%26+0+%26+0+%5C%5C+3+%26+-6+%26+3+%26+0+%5C%5C+-1+%26+3+%26+-3+%26+1+%5Cend%7Bpmatrix%7D+%5Cbegin%7Bpmatrix%7D+%5Cmathbf%7Bp%7D_0+%5C%5C+%5Cmathbf%7Bp%7D_1+%5C%5C+%5Cmathbf%7Bp%7D_2+%5C%5C+%5Cmathbf%7Bp%7D_3+%5Cend%7Bpmatrix%7D)

## 贝塞尔曲线的导数

![](https://www.zhihu.com/equation?tex=%5Cfrac%7Bd%7D%7Bdt%7D%5Cmathbf%7Bp%7D%28t%29+%3D+n+%5Csum_%7Bi%3D0%7D%5E%7Bn-1%7D+B_i%5E%7Bn-1%7D%28t%29%28%5Cmathbf%7Bp%7D_%7Bi%2B1%7D+-+%5Cmathbf%7Bp%7D_i%29)

导数本身也是贝塞尔曲线，但阶数降低1。

## 有理贝塞尔曲线 (Rational Bézier Curves)

引入权重![](https://www.zhihu.com/equation?tex=w_i)提供额外自由度，可精确表示圆等曲线：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28t%29+%3D+%5Cfrac%7B%5Csum_%7Bi%3D0%7D%5E%7Bn%7D+w_i+B_i%5En%28t%29+%5Cmathbf%7Bp%7D_i%7D%7B%5Csum_%7Bi%3D0%7D%5E%7Bn%7D+w_i+B_i%5En%28t%29%7D)

## 17.1.2 GPU 上的有界贝塞尔曲线 (Bounded Bézier Curves on GPU)

## 核心概念 (Core Concepts)

**有界贝塞尔曲线**：填充曲线与首尾控制点连线之间的区域。

## 实现细节 (Implementation Details)

对于二次贝塞尔曲线（控制点![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_0%2C+%5Cmathbf%7Bp%7D_1%2C+%5Cmathbf%7Bp%7D_2)），设置顶点纹理坐标：

- 
- 
- 

在像素着色器中评估标量函数：

![](https://www.zhihu.com/equation?tex=f%28u%2C+v%29+%3D+u%5E2+-+v)

- ：像素在曲线内部
- ：像素在曲线外部（discard）

## 应用场景

- TrueType 字体渲染
- 可扩展到有理二次曲线和三次曲线
- 支持抗锯齿处理
- 详见 Section 15.5（文本渲染）

## 17.1.3 连续性与分段贝塞尔曲线 (Continuity and Piecewise Bézier Curves)

## 核心概念 (Core Concepts)

**分段贝塞尔曲线 (Piecewise Bézier Curve)**：用多条低阶曲线段拼接，解决单一高阶曲线的问题。

## 连续性级别

连续性含义要求C^0位置连续曲线段在关节点相连：\mathbf{q}_3 = \mathbf{r}_0G^1几何连续切线方向相同（长度可不同）：(\mathbf{r}_1 - \mathbf{r}_0) = c(\mathbf{q}_3 - \mathbf{q}_2), c > 0C^1参数连续一阶导数连续且非零C^nn阶连续前n阶导数全部连续且非零

## 参数区间映射

当曲线段参数区间不同时，需进行映射：

![](https://www.zhihu.com/equation?tex=t%27+%3D+%5Cfrac%7Bt+-+t_1%7D%7Bt_2+-+t_1%7D)

## 连续性条件

为实现![](https://www.zhihu.com/equation?tex=C%5E1)连续，使用调整系数：

![](https://www.zhihu.com/equation?tex=c+%3D+%5Cfrac%7Bt_2+-+t_1%7D%7Bt_1+-+t_0%7D)

当所有曲线段的时间间隔相等时，![](https://www.zhihu.com/equation?tex=c+%3D+1)，即入射和出射切线向量相同。

## 17.1.4 三次 Hermite 插值 (Cubic Hermite Interpolation)

## 核心概念 (Core Concepts)

**Hermite 曲线**通过起止点![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_0%2C+%5Cmathbf%7Bp%7D_1)和起止切线![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bm%7D_0%2C+%5Cmathbf%7Bm%7D_1)定义，比贝塞尔曲线更直观易控制。

## Hermite 插值公式

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28t%29+%3D+%282t%5E3+-+3t%5E2+%2B+1%29%5Cmathbf%7Bp%7D_0+%2B+%28t%5E3+-+2t%5E2+%2B+t%29%5Cmathbf%7Bm%7D_0+%2B+%28t%5E3+-+t%5E2%29%5Cmathbf%7Bm%7D_1+%2B+%28-2t%5E3+%2B+3t%5E2%29%5Cmathbf%7Bp%7D_1)

**满足条件**：

- ，
- ，

## 混合函数 (Blending Functions)

函数表达式位置 \mathbf{p}_02t^3 - 3t^2 + 1切线 \mathbf{m}_0t^3 - 2t^2 + t切线 \mathbf{m}_1t^3 - t^2位置 \mathbf{p}_1-2t^3 + 3t^2

## 应用

- Nalu 演示中的头发渲染：使用粗糙控制头发进行动画和碰撞检测，计算切线后细分渲染三次曲线。

## 17.1.5 Kochanek-Bartels 曲线

## 核心概念 (Core Concepts)

用于连接多个 Hermite 曲线段，通过三个参数控制关节处的曲线行为。

## 张力参数 (Tension Parameter) -

控制切线长度，影响关节处的尖锐程度：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bm%7D_i+%3D+%5Cfrac%7B1-a%7D%7B2%7D%5Cleft%5B%28%5Cmathbf%7Bp%7D_i+-+%5Cmathbf%7Bp%7D_%7Bi-1%7D%29+%2B+%28%5Cmathbf%7Bp%7D_%7Bi%2B1%7D+-+%5Cmathbf%7Bp%7D_i%29%5Cright%5D)

- （默认）：标准 Catmull-Rom 样条
- ：更尖锐的弯曲（ 会产生循环）
- ：关节处更松弛

## 偏置参数 (Bias Parameter) -

影响切线方向：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bm%7D_i+%3D+%5Cfrac%7B%281-a%29%281%2Bb%29%7D%7B2%7D%28%5Cmathbf%7Bp%7D_i+-+%5Cmathbf%7Bp%7D_%7Bi-1%7D%29+%2B+%5Cfrac%7B%281-a%29%281-b%29%7D%7B2%7D%28%5Cmathbf%7Bp%7D_%7Bi%2B1%7D+-+%5Cmathbf%7Bp%7D_i%29)

- （默认）：均衡两个弦向量
- ：弯曲偏向  方向
- ：弯曲偏向  方向

## 连续性参数 (Continuity Parameter) -

引入入射切线![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bs%7D_i)和出射切线![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bd%7D_i)：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bs%7D_i+%3D+%5Cfrac%7B1-c%7D%7B2%7D%28%5Cmathbf%7Bp%7D_i+-+%5Cmathbf%7Bp%7D_%7Bi-1%7D%29+%2B+%5Cfrac%7B1%2Bc%7D%7B2%7D%28%5Cmathbf%7Bp%7D_%7Bi%2B1%7D+-+%5Cmathbf%7Bp%7D_i%29)

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bd%7D_i+%3D+%5Cfrac%7B1%2Bc%7D%7B2%7D%28%5Cmathbf%7Bp%7D_i+-+%5Cmathbf%7Bp%7D_%7Bi-1%7D%29+%2B+%5Cfrac%7B1-c%7D%7B2%7D%28%5Cmathbf%7Bp%7D_%7Bi%2B1%7D+-+%5Cmathbf%7Bp%7D_i%29)

- （默认）：
- ：产生尖角（仅 ）

## 完整公式（张力+偏置+连续性）

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bs%7D_i+%3D+%5Cfrac%7B%281-a%29%281%2Bb%29%281-c%29%7D%7B2%7D%28%5Cmathbf%7Bp%7D_i+-+%5Cmathbf%7Bp%7D_%7Bi-1%7D%29+%2B+%5Cfrac%7B%281-a%29%281-b%29%281%2Bc%29%7D%7B2%7D%28%5Cmathbf%7Bp%7D_%7Bi%2B1%7D+-+%5Cmathbf%7Bp%7D_i%29)

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bd%7D_i+%3D+%5Cfrac%7B%281-a%29%281%2Bb%29%281%2Bc%29%7D%7B2%7D%28%5Cmathbf%7Bp%7D_i+-+%5Cmathbf%7Bp%7D_%7Bi-1%7D%29+%2B+%5Cfrac%7B%281-a%29%281-b%29%281-c%29%7D%7B2%7D%28%5Cmathbf%7Bp%7D_%7Bi%2B1%7D+-+%5Cmathbf%7Bp%7D_i%29)

## 非均匀时间间隔调整

当曲线段时间间隔不同时，需调整切线：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bs%7D%27_i+%3D+%5Cmathbf%7Bs%7D_i+%5Cfrac%7B2%5CDelta_i%7D%7B%5CDelta_%7Bi-1%7D+%2B+%5CDelta_i%7D%2C+%5Cquad+%5Cmathbf%7Bd%7D%27_i+%3D+%5Cmathbf%7Bd%7D_i+%5Cfrac%7B2%5CDelta_%7Bi-1%7D%7D%7B%5CDelta_%7Bi-1%7D+%2B+%5CDelta_i%7D)

其中![](https://www.zhihu.com/equation?tex=%5CDelta_i+%3D+t_%7Bi%2B1%7D+-+t_i)。

## 17.1.6 B 样条 (B-Splines)

## 核心概念 (Core Concepts)

B 样条使用移位基函数![](https://www.zhihu.com/equation?tex=%5Cbeta%5En)和控制点![](https://www.zhihu.com/equation?tex=c_k)表示：

![](https://www.zhihu.com/equation?tex=s%5En%28t%29+%3D+%5Csum_k+c_k+%5Cbeta%5En%28t+-+k%29)

**均匀三次 B 样条 (Uniform Cubic B-Spline)**具有![](https://www.zhihu.com/equation?tex=C%5E2)连续性。

## 三次 B 样条基函数

![](https://www.zhihu.com/equation?tex=%5Cbeta%5E3%28t%29+%3D+%5Cbegin%7Bcases%7D+0%2C+%26+%7Ct%7C+%5Cgeq+2+%5C%5C+%5Cfrac%7B1%7D%7B6%7D%282+-+%7Ct%7C%29%5E3%2C+%26+1+%5Cleq+%7Ct%7C+%3C+2+%5C%5C+%5Cfrac%7B2%7D%7B3%7D+-+%5Cfrac%7B1%7D%7B2%7D%7Ct%7C%5E2%282+-+%7Ct%7C%29%2C+%26+%7Ct%7C+%3C+1+%5Cend%7Bcases%7D)

## 曲线段求值

对于参数![](https://www.zhihu.com/equation?tex=i+%2B+%5Calpha)（![](https://www.zhihu.com/equation?tex=%5Calpha+%5Cin+%5B0%2C+1%29)），使用四个控制点：

![](https://www.zhihu.com/equation?tex=s%5E3%28i+%2B+%5Calpha%29+%3D+w_0%28%5Calpha%29c_%7Bi-1%7D+%2B+w_1%28%5Calpha%29c_i+%2B+w_2%28%5Calpha%29c_%7Bi%2B1%7D+%2B+w_3%28%5Calpha%29c_%7Bi%2B2%7D)

## 权重函数

![](https://www.zhihu.com/equation?tex=w_0%28%5Calpha%29+%3D+%5Cfrac%7B1%7D%7B6%7D%281+-+%5Calpha%29%5E3)

![](https://www.zhihu.com/equation?tex=w_1%28%5Calpha%29+%3D+%5Cfrac%7B2%7D%7B3%7D+-+%5Cfrac%7B1%7D%7B2%7D%5Calpha%5E2%282+-+%5Calpha%29)

![](https://www.zhihu.com/equation?tex=w_2%28%5Calpha%29+%3D+%5Cfrac%7B2%7D%7B3%7D+-+%5Cfrac%7B1%7D%7B2%7D%281-%5Calpha%29%5E2%281+%2B+%5Calpha%29)

![](https://www.zhihu.com/equation?tex=w_3%28%5Calpha%29+%3D+%5Cfrac%7B1%7D%7B6%7D%5Calpha%5E3)

## 关键特性

- 局部支撑 (Local Support)：任意时刻只使用4个控制点
- 连续性：多段拼接后仍保持光滑
- 曲线不一定通过控制点
- 可扩展到非均匀 B 样条以获得更大灵活性

## 17.2 参数曲面 (Parametric Curved Surfaces)

参数曲面是参数曲线的自然扩展，从一维到二维。参数曲面通过少量控制点定义，运行时可细分为任意数量的三角形，实现质量与性能的权衡。

## 17.2.1 贝塞尔曲面片 (Bézier Patches)

## 核心概念 (Core Concepts)

**双线性插值 (Bilinear Interpolation)**是最简单的参数曲面，使用四个点![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Ba%7D%2C+%5Cmathbf%7Bb%7D%2C+%5Cmathbf%7Bc%7D%2C+%5Cmathbf%7Bd%7D)和两个参数![](https://www.zhihu.com/equation?tex=%28u%2C+v%29)：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28u%2C+v%29+%3D+%281-u%29%281-v%29%5Cmathbf%7Ba%7D+%2B+u%281-v%29%5Cmathbf%7Bb%7D+%2B+%281-u%29v%5Cmathbf%7Bc%7D+%2B+uv%5Cmathbf%7Bd%7D)

参数域为![](https://www.zhihu.com/equation?tex=%28u%2C+v%29+%5Cin+%5B0%2C1%5D+%5Ctimes+%5B0%2C1%5D)，这种矩形域曲面称为**曲面片 (Patch)**。

## de Casteljau 算法（曲面片）

对于![](https://www.zhihu.com/equation?tex=%28n%2B1%29%5E2)个控制点![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_%7Bi%2Cj%7D)（![](https://www.zhihu.com/equation?tex=i%2C+j+%5Cin+%5B0%2C+n%5D)），递推公式为：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_%7Bi%2Cj%7D%5Ek%28u%2Cv%29+%3D+%281-u%29%281-v%29%5Cmathbf%7Bp%7D_%7Bi%2Cj%7D%5E%7Bk-1%7D+%2B+u%281-v%29%5Cmathbf%7Bp%7D_%7Bi%2Cj%2B1%7D%5E%7Bk-1%7D+%2B+%281-u%29v%5Cmathbf%7Bp%7D_%7Bi%2B1%2Cj%7D%5E%7Bk-1%7D+%2B+uv%5Cmathbf%7Bp%7D_%7Bi%2B1%2Cj%2B1%7D%5E%7Bk-1%7D)

曲面上点为![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28u%2Cv%29+%3D+%5Cmathbf%7Bp%7D_%7B0%2C0%7D%5En%28u%2Cv%29)。

## Bernstein 形式（曲面片）

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28u%2C+v%29+%3D+%5Csum_%7Bi%3D0%7D%5E%7Bm%7D+%5Csum_%7Bj%3D0%7D%5E%7Bn%7D+B_i%5Em%28u%29+B_j%5En%28v%29+%5Cmathbf%7Bp%7D_%7Bi%2Cj%7D)

度数可记为![](https://www.zhihu.com/equation?tex=m+%5Ctimes+n)，通常![](https://www.zhihu.com/equation?tex=m+%3D+n)。

## 关键性质

- 角点插值：曲面片通过四个角控制点
- 边界曲线：每条边界是由边界控制点定义的贝塞尔曲线
- 凸包性：曲面位于控制点凸包内
- 变换不变性：先变换控制点再生成曲面 = 生成曲面后再变换

## 偏导数与法向量

![](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cmathbf%7Bp%7D%28u%2Cv%29%7D%7B%5Cpartial+u%7D+%3D+m+%5Csum_%7Bi%3D0%7D%5E%7Bm-1%7D+%5Csum_%7Bj%3D0%7D%5E%7Bn%7D+B_i%5E%7Bm-1%7D%28u%29+B_j%5En%28v%29+%5B%5Cmathbf%7Bp%7D_%7Bi%2B1%2Cj%7D+-+%5Cmathbf%7Bp%7D_%7Bi%2Cj%7D%5D)

法向量：![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bn%7D%28u%2Cv%29+%3D+%5Cfrac%7B%5Cpartial+%5Cmathbf%7Bp%7D%7D%7B%5Cpartial+u%7D+%5Ctimes+%5Cfrac%7B%5Cpartial+%5Cmathbf%7Bp%7D%7D%7B%5Cpartial+v%7D)

## 有理贝塞尔曲面片 (Rational Bézier Patches)

引入权重![](https://www.zhihu.com/equation?tex=w_%7Bi%2Cj%7D)提供更多自由度：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28u%2Cv%29+%3D+%5Cfrac%7B%5Csum_%7Bi%3D0%7D%5E%7Bm%7D+%5Csum_%7Bj%3D0%7D%5E%7Bn%7D+w_%7Bi%2Cj%7D+B_i%5Em%28u%29+B_j%5En%28v%29+%5Cmathbf%7Bp%7D_%7Bi%2Cj%7D%7D%7B%5Csum_%7Bi%3D0%7D%5E%7Bm%7D+%5Csum_%7Bj%3D0%7D%5E%7Bn%7D+w_%7Bi%2Cj%7D+B_i%5Em%28u%29+B_j%5En%28v%29%7D)

## 17.2.2 贝塞尔三角形 (Bézier Triangles)

## 核心概念 (Core Concepts)

贝塞尔三角形使用三角形域和**重心坐标 (Barycentric Coordinates)**![](https://www.zhihu.com/equation?tex=%28u%2C+v%29)。

- 度数为  时，每边有  个控制点
- 控制点记为 ，满足 ，
- 总控制点数：

## de Casteljau 算法（三角形）

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_%7Bi%2Cj%2Ck%7D%5El%28u%2Cv%29+%3D+u%5Cmathbf%7Bp%7D_%7Bi%2B1%2Cj%2Ck%7D%5E%7Bl-1%7D+%2B+v%5Cmathbf%7Bp%7D_%7Bi%2Cj%2B1%2Ck%7D%5E%7Bl-1%7D+%2B+%281-u-v%29%5Cmathbf%7Bp%7D_%7Bi%2Cj%2Ck%2B1%7D%5E%7Bl-1%7D)

曲面点为![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28u%2Cv%29+%3D+%5Cmathbf%7Bp%7D_%7B000%7D%5En%28u%2Cv%29)。

## Bernstein 形式（三角形）

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28u%2Cv%29+%3D+%5Csum_%7Bi%2Bj%2Bk%3Dn%7D+B_%7Bijk%7D%5En%28u%2Cv%29+%5Cmathbf%7Bp%7D_%7Bijk%7D)

其中 Bernstein 多项式：

![](https://www.zhihu.com/equation?tex=B_%7Bijk%7D%5En%28u%2Cv%29+%3D+%5Cfrac%7Bn%21%7D%7Bi%21j%21k%21%7D+u%5Ei+v%5Ej+%281-u-v%29%5Ek%2C+%5Cquad+i%2Bj%2Bk%3Dn)

## 偏导数

![](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cmathbf%7Bp%7D%7D%7B%5Cpartial+u%7D+%3D+%5Csum_%7Bi%2Bj%2Bk%3Dn-1%7D+n+B_%7Bijk%7D%5E%7Bn-1%7D%28u%2Cv%29+%28%5Cmathbf%7Bp%7D_%7Bi%2B1%2Cj%2Ck%7D+-+%5Cmathbf%7Bp%7D_%7Bi%2Cj%2Ck%2B1%7D%29)

![](https://www.zhihu.com/equation?tex=%5Cfrac%7B%5Cpartial+%5Cmathbf%7Bp%7D%7D%7B%5Cpartial+v%7D+%3D+%5Csum_%7Bi%2Bj%2Bk%3Dn-1%7D+n+B_%7Bijk%7D%5E%7Bn-1%7D%28u%2Cv%29+%28%5Cmathbf%7Bp%7D_%7Bi%2Cj%2B1%2Ck%7D+-+%5Cmathbf%7Bp%7D_%7Bi%2Cj%2Ck%2B1%7D%29)

## 17.2.3 连续性 (Continuity)

## 连续性

两个双三次贝塞尔曲面片共享边界控制点：![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Ba%7D_%7B3j%7D+%3D+%5Cmathbf%7Bb%7D_%7B0j%7D)

## 连续性

边界两侧各两行控制点必须满足：

- 、、 共线
- 线段比例相同：（对所有  相同）

## 四曲面片共享角点

共享角点周围的9个控制点必须：

- 位于同一平面
- 形成双线性曲面片

## 连续性要求

应用最低要求纹理映射C^1反射/着色G^1（C^1 更好）

## 17.2.4 PN 三角形 (PN Triangles)

## 核心概念 (Core Concepts)

**PN 三角形**（Point-Normal Triangles，也称 N-patches）由 Vlachos 等人提出，仅需顶点位置和法线即可生成三次贝塞尔三角形曲面，改善轮廓和着色效果。

## 三次贝塞尔三角形展开

设![](https://www.zhihu.com/equation?tex=w+%3D+1+-+u+-+v)：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%28u%2Cv%29+%3D+u%5E3%5Cmathbf%7Bp%7D_%7B300%7D+%2B+v%5E3%5Cmathbf%7Bp%7D_%7B030%7D+%2B+w%5E3%5Cmathbf%7Bp%7D_%7B003%7D+%2B+3u%5E2v%5Cmathbf%7Bp%7D_%7B210%7D+%2B+3u%5E2w%5Cmathbf%7Bp%7D_%7B201%7D)

![](https://www.zhihu.com/equation?tex=%2B+3uv%5E2%5Cmathbf%7Bp%7D_%7B120%7D+%2B+3v%5E2w%5Cmathbf%7Bp%7D_%7B021%7D+%2B+3vw%5E2%5Cmathbf%7Bp%7D_%7B012%7D+%2B+3uw%5E2%5Cmathbf%7Bp%7D_%7B102%7D+%2B+6uvw%5Cmathbf%7Bp%7D_%7B111%7D)

## 边界控制点计算

将点投影到切平面：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_%7B210%7D+%3D+%5Cfrac%7B1%7D%7B3%7D%5Cleft%282%5Cmathbf%7Bp%7D_%7B300%7D+%2B+%5Cmathbf%7Bp%7D_%7B030%7D+-+%28%5Cmathbf%7Bn%7D_%7B200%7D+%5Ccdot+%28%5Cmathbf%7Bp%7D_%7B030%7D+-+%5Cmathbf%7Bp%7D_%7B300%7D%29%29%5Cmathbf%7Bn%7D_%7B200%7D%5Cright%29)

## 内部控制点计算

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_%7B111%7D+%3D+%5Cfrac%7B1%7D%7B4%7D%28%5Cmathbf%7Bp%7D_%7B210%7D+%2B+%5Cmathbf%7Bp%7D_%7B120%7D+%2B+%5Cmathbf%7Bp%7D_%7B102%7D+%2B+%5Cmathbf%7Bp%7D_%7B201%7D+%2B+%5Cmathbf%7Bp%7D_%7B021%7D+%2B+%5Cmathbf%7Bp%7D_%7B012%7D%29+-+%5Cfrac%7B1%7D%7B6%7D%28%5Cmathbf%7Bp%7D_%7B300%7D+%2B+%5Cmathbf%7Bp%7D_%7B030%7D+%2B+%5Cmathbf%7Bp%7D_%7B003%7D%29)

## 二次法线插值

使用二次贝塞尔三角形插值法线（避免线性插值无法描述拐点）：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bn%7D%28u%2Cv%29+%3D+u%5E2%5Cmathbf%7Bn%7D_%7B200%7D+%2B+v%5E2%5Cmathbf%7Bn%7D_%7B020%7D+%2B+w%5E2%5Cmathbf%7Bn%7D_%7B002%7D+%2B+2%28uv%5Cmathbf%7Bn%7D_%7B110%7D+%2B+uw%5Cmathbf%7Bn%7D_%7B101%7D+%2B+vw%5Cmathbf%7Bn%7D_%7B011%7D%29)

边界法线通过反射计算：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bn%7D%27_%7B110%7D+%3D+%5Cmathbf%7Bn%7D_%7B200%7D+%2B+%5Cmathbf%7Bn%7D_%7B020%7D+-+2%5Cfrac%7B%28%5Cmathbf%7Bn%7D_%7B200%7D+%2B+%5Cmathbf%7Bn%7D_%7B020%7D%29+%5Ccdot+%28%5Cmathbf%7Bp%7D_%7B030%7D+-+%5Cmathbf%7Bp%7D_%7B300%7D%29%7D%7B%28%5Cmathbf%7Bp%7D_%7B030%7D+-+%5Cmathbf%7Bp%7D_%7B300%7D%29+%5Ccdot+%28%5Cmathbf%7Bp%7D_%7B030%7D+-+%5Cmathbf%7Bp%7D_%7B300%7D%29%7D%28%5Cmathbf%7Bp%7D_%7B030%7D+-+%5Cmathbf%7Bp%7D_%7B300%7D%29)

## LOD 细分

- LOD 0：原始三角形
- LOD n：每边引入  个新顶点，生成  个子三角形

## 优缺点

- ✅ 改善轮廓和形状
- ✅ 仅需顶点+法线，无需邻居信息
- ❌ 仅  连续（但法线连续模拟 ）
- ❌ 折痕控制困难

## 17.2.5 Phong 曲面细分 (Phong Tessellation)

## 核心概念 (Core Concepts)

Phong 曲面细分比 PN 三角形更快更简单，是 Phong 着色的几何版本。

## 算法步骤

- 基础三角形点：
- 切平面投影函数：
- 投影点插值：
- 最终公式（带形状因子 ）：

## 实现细节

- 推荐
- 结果是二次曲面（比 PN 三角形的三次更低）
- 法线使用标准线性插值
- 仅需顶点、法线和 ，评估极快

## 17.2.6 B 样条曲面 (B-Spline Surfaces)

## 核心概念 (Core Concepts)

B 样条曲面是 B 样条曲线的二维扩展：

![](https://www.zhihu.com/equation?tex=s%5En%28u%2Cv%29+%3D+%5Csum_k+%5Csum_l+c_%7Bk%2Cl%7D+%5Cbeta%5En%28u-k%29+%5Cbeta%5En%28v-l%29)

## 双三次 B 样条曲面片

- 使用  基函数
- 需要  控制点
- 实际曲面片位于最内部  控制点区域内
- Catmull-Clark 细分曲面的基础

## 17.3 隐式曲面 (Implicit Surfaces)

隐式曲面通过标量函数![](https://www.zhihu.com/equation?tex=f%28%5Cmathbf%7Bp%7D%29)定义，其中![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D+%3D+%28x%2C+y%2C+z%29)。曲面由满足![](https://www.zhihu.com/equation?tex=f%28%5Cmathbf%7Bp%7D%29+%3D+0)的所有点构成。

## 核心概念 (Core Concepts)

## 有符号距离函数 (Signed Distance Function, SDF)

**SDF**是最常用的隐式表示，返回点到曲面的最短距离：

- ：点在曲面内部
- ：点在曲面上
- ：点在曲面外部

## 基本图元 (Primitives)

图元SDF 公式球体（半径 r）f(\mathbf{p}) = \|\mathbf{p}\| - r平面（法线 \mathbf{n}，距离 d）f(\mathbf{p}) = \mathbf{n} \cdot \mathbf{p} + d立方体（半边长 \mathbf{b}）f(\mathbf{p}) = \|\max(\|\mathbf{p}\| - \mathbf{b}, 0)\|

## 梯度与法向量

SDF 的梯度即为曲面法向量：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bn%7D%28%5Cmathbf%7Bp%7D%29+%3D+%5Cnabla+f%28%5Cmathbf%7Bp%7D%29+%3D+%5Cleft%28%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+x%7D%2C+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+y%7D%2C+%5Cfrac%7B%5Cpartial+f%7D%7B%5Cpartial+z%7D%5Cright%29)

## CSG 操作 (Constructive Solid Geometry)

使用布尔运算组合隐式曲面：

操作公式并集 (Union)f(\mathbf{p}) = \min(f_1(\mathbf{p}), f_2(\mathbf{p}))交集 (Intersection)f(\mathbf{p}) = \max(f_1(\mathbf{p}), f_2(\mathbf{p}))差集 (Difference)f(\mathbf{p}) = \max(f_1(\mathbf{p}), -f_2(\mathbf{p}))

## 光滑混合 (Smooth Blending)

## Soft Objects / Metaballs

使用衰减函数替代硬边界：

![](https://www.zhihu.com/equation?tex=f%28%5Cmathbf%7Bp%7D%29+%3D+T+-+%5Csum_i+b_i%28%5C%7C%5Cmathbf%7Bp%7D+-+%5Cmathbf%7Bc%7D_i%5C%7C%29)

其中![](https://www.zhihu.com/equation?tex=T)为阈值，![](https://www.zhihu.com/equation?tex=b_i)为混合函数（blob function）。

## 常用混合函数

**Wyvill 函数**（又称 soft object 函数）：

![](https://www.zhihu.com/equation?tex=b%28r%29+%3D+%5Cbegin%7Bcases%7D++%281+-+r%5E2%2FR%5E2%29%5E3%2C+%26+0+%5Cleq+r+%5Cleq+R+%5C%5C+0%2C+%26+r+%3E+R++%5Cend%7Bcases%7D)

其中![](https://www.zhihu.com/equation?tex=R)为影响半径。

## 光滑最小值 (Smooth Minimum)

用于平滑过渡两个 SDF：

![](https://www.zhihu.com/equation?tex=f%28%5Cmathbf%7Bp%7D%29+%3D+%5Ctext%7Bsmin%7D%28f_1%28%5Cmathbf%7Bp%7D%29%2C+f_2%28%5Cmathbf%7Bp%7D%29%2C+k%29)

**多项式光滑最小值**：

![](https://www.zhihu.com/equation?tex=%5Ctext%7Bsmin%7D%28a%2C+b%2C+k%29+%3D+%5Cmin%28a%2C+b%29+-+%5Cfrac%7B1%7D%7B4k%7D%28%5Cmax%28k+-+%7Ca-b%7C%2C+0%29%29%5E2)

参数![](https://www.zhihu.com/equation?tex=k)控制混合程度。

## 光线步进 (Ray Marching)

渲染 SDF 的主要方法，也称为**Sphere Tracing**：

float rayMarch(vec3 ro, vec3 rd) {
    float t = 0.0;
    for (int i = 0; i < MAX_STEPS; i++) {
        vec3 p = ro + t * rd;
        float d = sceneSDF(p);
        if (d < EPSILON) return t;  // 命中曲面
        t += d;                      // 安全步进距离
        if (t > MAX_DIST) break;
    }
    return -1.0;  // 未命中
}

**关键特性**：

- 每次步进  为当前点到曲面的最近距离
- 保证不会穿过曲面
- 适合 GPU 像素着色器实现
- Shadertoy 中广泛使用

## 应用场景

- 程序化建模：通过 SDF 组合创建复杂形状
- 软阴影：使用 SDF 估算遮挡
- 环境遮蔽：基于距离场采样
- 体积渲染：云、烟雾等效果
- 碰撞检测：快速距离查询

## 17.4 细分曲线 (Subdivision Curves)

细分曲线通过迭代细化控制点序列生成光滑曲线，是细分曲面的一维基础。

## 核心概念 (Core Concepts)

## Chaikin 算法（角切割）

**最简单的细分方案**，每次迭代：

- 在每条边的  和  处插入新点
- 丢弃原始顶点

**数学表示**：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_%7B2i%7D%5E%7Bk%2B1%7D+%3D+%5Cfrac%7B3%7D%7B4%7D%5Cmathbf%7Bp%7D_i%5Ek+%2B+%5Cfrac%7B1%7D%7B4%7D%5Cmathbf%7Bp%7D_%7Bi%2B1%7D%5Ek)

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_%7B2i%2B1%7D%5E%7Bk%2B1%7D+%3D+%5Cfrac%7B1%7D%7B4%7D%5Cmathbf%7Bp%7D_i%5Ek+%2B+%5Cfrac%7B3%7D%7B4%7D%5Cmathbf%7Bp%7D_%7Bi%2B1%7D%5Ek)

**特性**：

- 产生二次 B 样条曲线
- 连续
- 每次迭代点数近似翻倍
- 极限曲线 (Limit Curve) 存在且光滑

## 四点细分 (Four-Point Scheme)

**插值型细分**，新点同时依赖4个邻近点：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_%7B2i%2B1%7D%5E%7Bk%2B1%7D+%3D+%5Cfrac%7B1%7D%7B16%7D%28-%5Cmathbf%7Bp%7D_%7Bi-1%7D%5Ek+%2B+9%5Cmathbf%7Bp%7D_i%5Ek+%2B+9%5Cmathbf%7Bp%7D_%7Bi%2B1%7D%5Ek+-+%5Cmathbf%7Bp%7D_%7Bi%2B2%7D%5Ek%29+%2B+%5Comega%28%5Cmathbf%7Bp%7D_%7Bi-1%7D%5Ek+-+%5Cmathbf%7Bp%7D_i%5Ek+-+%5Cmathbf%7Bp%7D_%7Bi%2B1%7D%5Ek+%2B+%5Cmathbf%7Bp%7D_%7Bi%2B2%7D%5Ek%29)

其中![](https://www.zhihu.com/equation?tex=%5Comega)为张力参数（tension parameter）：

- ：标准四点细分
- ：三次 B 样条

**特性**：

- 插值型：原始控制点保留在曲线上
- 连续（ 适当时）

## 细分规则对比

方案类型连续性极限曲线Chaikin逼近型C^1二次 B 样条四点细分插值型C^1—三次 B 样条细分逼近型C^2三次 B 样条

## 17.5 细分曲面 (Subdivision Surfaces)

细分曲面是细分曲线到二维的扩展，通过迭代细化网格生成光滑曲面。

## 17.5.1 Loop 细分 (Loop Subdivision)

## 核心概念 (Core Concepts)

**Loop 细分**（由 Charles Loop 于 1987 年提出）专用于**三角形网格**。

## 细分步骤

- 边点 (Edge Point)：在每条边上插入新顶点
- 顶点更新 (Vertex Update)：更新原始顶点位置

## 边点计算

对于边![](https://www.zhihu.com/equation?tex=%28%5Cmathbf%7Bp%7D_0%2C+%5Cmathbf%7Bp%7D_1%29)，两侧顶点为![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_2%2C+%5Cmathbf%7Bp%7D_3)：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Be%7D+%3D+%5Cfrac%7B3%7D%7B8%7D%28%5Cmathbf%7Bp%7D_0+%2B+%5Cmathbf%7Bp%7D_1%29+%2B+%5Cfrac%7B1%7D%7B8%7D%28%5Cmathbf%7Bp%7D_2+%2B+%5Cmathbf%7Bp%7D_3%29)

## 顶点更新

对于**度数 (Valence)**为![](https://www.zhihu.com/equation?tex=n)的顶点![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D)：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%27+%3D+%281+-+n%5Cbeta%29%5Cmathbf%7Bp%7D+%2B+%5Cbeta+%5Csum_%7Bi%3D0%7D%5E%7Bn-1%7D+%5Cmathbf%7Bq%7D_i)

其中![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bq%7D_i)为邻居顶点。

**参数**（Warren 公式）：

![](https://www.zhihu.com/equation?tex=%5Cbeta+%3D+%5Cfrac%7B1%7D%7Bn%7D%5Cleft%28%5Cfrac%7B5%7D%7B8%7D+-+%5Cleft%28%5Cfrac%7B3%7D%7B8%7D+%2B+%5Cfrac%7B1%7D%7B4%7D%5Ccos%5Cfrac%7B2%5Cpi%7D%7Bn%7D%5Cright%29%5E2%5Cright%29)

或简化版本：![](https://www.zhihu.com/equation?tex=%5Cbeta+%3D+%5Cfrac%7B3%7D%7B8n%7D)（当![](https://www.zhihu.com/equation?tex=n+%3E+3)）

## 关键概念

- 普通顶点 (Ordinary/Regular Vertex)：度数 = 6
- 异常顶点 (Extraordinary Vertex)：度数 ≠ 6
- 异常顶点处连续性降低至 ，其他处为

## 17.5.2 Catmull-Clark 细分 (Catmull-Clark Subdivision)

## 核心概念 (Core Concepts)

**Catmull-Clark 细分**适用于**任意多边形网格**，产生**双三次 B 样条曲面**（在普通区域）。

## 细分步骤

- 面点 (Face Point)：每个面中心添加新点
- 边点 (Edge Point)：每条边中点添加新点
- 顶点更新：更新原始顶点位置

## 面点计算

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bf%7D+%3D+%5Cfrac%7B1%7D%7Bm%7D%5Csum_%7Bi%3D0%7D%5E%7Bm-1%7D+%5Cmathbf%7Bp%7D_i)

其中![](https://www.zhihu.com/equation?tex=m)为面的顶点数。

## 边点计算

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Be%7D+%3D+%5Cfrac%7B1%7D%7B4%7D%28%5Cmathbf%7Bp%7D_0+%2B+%5Cmathbf%7Bp%7D_1+%2B+%5Cmathbf%7Bf%7D_0+%2B+%5Cmathbf%7Bf%7D_1%29)

其中![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D_0%2C+%5Cmathbf%7Bp%7D_1)为边端点，![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bf%7D_0%2C+%5Cmathbf%7Bf%7D_1)为相邻面点。

## 顶点更新

对于度数为![](https://www.zhihu.com/equation?tex=n)的顶点：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%27+%3D+%5Cfrac%7Bn-2%7D%7Bn%7D%5Cmathbf%7Bp%7D+%2B+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bi%3D0%7D%5E%7Bn-1%7D%5Cmathbf%7Bq%7D_i+%2B+%5Cfrac%7B1%7D%7Bn%5E2%7D%5Csum_%7Bi%3D0%7D%5E%7Bn-1%7D%5Cmathbf%7Bf%7D_i)

其中![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bq%7D_i)为邻居顶点，![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bf%7D_i)为相邻面点。

## 关键特性

- 普通顶点：度数 = 4
- 一次细分后所有面变为四边形
- 普通区域等价于双三次 B 样条
- 电影工业标准（Pixar 广泛使用）

## 17.5.3 分段光滑细分 (Piecewise Smooth Subdivision)

## 折痕与角点 (Creases and Corners)

实际模型需要**锐利特征**，通过标记边/顶点实现：

特征描述折痕边 (Crease Edge)边两侧曲面不光滑连接角点 (Corner Vertex)顶点处多个曲面尖锐相交飞镖顶点 (Dart Vertex)恰好一条折痕边的内部点

## 折痕边规则

对于折痕边上的边点：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Be%7D+%3D+%5Cfrac%7B1%7D%7B2%7D%28%5Cmathbf%7Bp%7D_0+%2B+%5Cmathbf%7Bp%7D_1%29)

不使用相邻面信息。

## 角点规则

角点位置在细分过程中**保持不变**：

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%27+%3D+%5Cmathbf%7Bp%7D)

## 半锐利折痕 (Semi-Sharp Creases)

引入**锐利度 (Sharpness)**参数![](https://www.zhihu.com/equation?tex=s)：

- ：完全光滑
- ：完全锐利
- 整数 ：前  次细分使用折痕规则，之后使用光滑规则

## 17.5.4 位移细分 (Displaced Subdivision)

## 核心概念 (Core Concepts)

结合**细分曲面**与**位移贴图 (Displacement Mapping)**：

- 细分基础网格至足够密度
- 沿法向量按位移贴图值偏移顶点

![](https://www.zhihu.com/equation?tex=%5Cmathbf%7Bp%7D%27+%3D+%5Cmathbf%7Bp%7D+%2B+d%28u%2Cv%29+%5Ccdot+%5Cmathbf%7Bn%7D)

其中![](https://www.zhihu.com/equation?tex=d%28u%2Cv%29)为位移贴图采样值。

## 实现细节

- 需要足够的细分级别以捕捉位移细节
- 通常与自适应细分结合
- 法线需重新计算或使用法线贴图

## 17.5.5 法线、纹理与颜色插值 (Normal, Texture, and Color Interpolation)

## 法线处理

- 极限法线 (Limit Normal)：细分收敛后的法线
- 可在域着色器中直接计算
- 异常顶点处需特殊处理

## 属性插值

顶点属性（UV、颜色等）可以：

- 随几何细分：使用相同细分规则
- 线性插值：忽略细分权重
- 独立细分：属性使用不同规则

## 17.6 高效曲面细分 (Efficient Tessellation)

GPU 曲面细分管线提供硬件加速的曲面细分能力。

## 17.6.1 分数曲面细分 (Fractional Tessellation)

## 核心概念 (Core Concepts)

**分数曲面细分**允许非整数细分因子，实现**平滑 LOD 过渡**。

## 硬件细分模式

模式描述integer整数细分，可能产生跳变fractional_even偶数分数细分fractional_odd奇数分数细分

## 边细分因子

每条边可独立设置细分因子，内部细分因子控制面内部划分。

## 对称性问题

分数细分需保持**对称性**以避免相邻曲面片之间的裂缝。Moreton 提出对称点分布方案确保无缝连接。

## 17.6.2 自适应曲面细分 (Adaptive Tessellation)

## 核心概念 (Core Concepts)

根据**曲率、屏幕大小、距离**等因素动态调整细分级别。

## 细分终止条件

- 曲率测试：评估边中点偏离直线的距离

![](https://www.zhihu.com/equation?tex=%5Ctext%7Bflatness%7D+%3D+%5Cfrac%7Bl%7D%7B%5C%7C%5Cmathbf%7Ba%7D+-+%5Cmathbf%7Bb%7D%5C%7C%7D)

- 视锥裁剪：边包围球是否在视锥内
- 背面剔除：基于法线方向
- 屏幕空间覆盖：投影边长度

## 屏幕空间投影

边![](https://www.zhihu.com/equation?tex=%28%5Cmathbf%7Ba%7D%2C+%5Cmathbf%7Bb%7D%29)的屏幕投影估算：

![](https://www.zhihu.com/equation?tex=s+%3D+%5Cfrac%7B%28%5Cmathbf%7Ba%7D%27+-+%5Cmathbf%7Bb%7D%27%29+%5Ccdot+%28%5Cmathbf%7Ba%7D%27+-+%5Cmathbf%7Bb%7D%27%29%7D%7B%5Cmathbf%7Bv%7D+%5Ccdot+%28%5Cmathbf%7Ba%7D%27+-+%5Cmathbf%7Be%7D%29%7D)

细分条件：![](https://www.zhihu.com/equation?tex=s+%3E+t%5E2)，其中![](https://www.zhihu.com/equation?tex=t)为阈值。

## 考虑因素

- 视锥内部
- 正面朝向
- 屏幕空间大
- 靠近轮廓

## 裂缝避免

- 边细分因子仅基于边本身信息
- 相邻曲面片共享边必须产生相同细分
- 限制四叉树：相邻区域细分级别差最多为1

## Split and Dice

递归分割曲面片直到达到目标三角形大小：

- 测试当前曲面片是否足够小
- 若否，分割为4个子曲面片
- 递归处理每个子曲面片
- 生成四叉树结构

**分数分割 (Fractional Split)**：

- 平滑引入分割点避免跳变
- 分割点从边端点向中心移动

## 17.6.3 快速 Catmull-Clark 曲面细分 (Fast Catmull-Clark Tessellation)

## 逼近方法 (Approximating Approaches)

**Loop-Schaefer 方法**：将 Catmull-Clark 曲面片转换为双三次贝塞尔曲面片。

## 普通曲面片（度数=4的顶点）

使用![](https://www.zhihu.com/equation?tex=4+%5Ctimes+4)控制点邻域，通过**掩码 (Mask)**计算贝塞尔控制点。

## 异常曲面片

当顶点度数![](https://www.zhihu.com/equation?tex=n+%5Cneq+4)时，使用特殊掩码。结果是**逼近**而非精确。

## 切线曲面片 (Tangent Patches)

用于计算平滑法线，解决![](https://www.zhihu.com/equation?tex=C%5E0)边界的着色问题。

## 特征自适应细分 (Feature Adaptive Subdivision, FAS)

**Pixar OpenSubdiv**实现的方法：

- 核心思想：普通面直接渲染为 B 样条曲面片
- 仅对异常面递归细分
- 细分到最大级别或全部变为普通面

## 过渡曲面片 (Transition Patches)

处理不同细分级别邻居：

- 分割为多个子曲面片
- 使用不同着色器变体

## 优势

- 支持折痕和半锐利折痕
- 基础网格可动画（索引表独立于顶点位置）
- 层次细节和自适应 LOD

## 自适应四叉树 (Adaptive Quadtrees)

**Brainerd 等人**提出的方法：

- 每个基础网格四边形提交为单个细分图元
- 预计算细分计划（四叉树编码层次细分）
- 域着色器中遍历四叉树找到正确子曲面片

## 优势

- 精确渲染 Catmull-Clark 曲面
- 支持折痕等拓扑特征
- 更均匀的细分结果
- 比 FAS 更高效

## 延伸阅读与资源 (Further Reading and Resources)

## 书籍推荐

主题推荐书籍几何建模入门Mortenson 《Geometric Modeling》CAGD 全面参考Farin 《Curves and Surfaces for CAGD》隐式曲面Gomes 等 《Implicit Curves and Surfaces》细分曲面Warren & Heimer 《Subdivision Methods for Geometric Design》

## 在线资源

- OpenSubdiv：Pixar 开源细分曲面库
- Shadertoy：SDF 和光线步进示例
- SIGGRAPH Course Notes：细分曲面教程

> **章节总结**：本章涵盖了从基础参数曲线（贝塞尔、B 样条）到高级细分曲面（Loop、Catmull-Clark）的完整技术栈，以及 GPU 硬件加速曲面细分的实现策略。核心要点包括：连续性要求、自适应细分策略、以及工业标准 Catmull-Clark 细分的高效实现方法。


---

# 有哪些和 AI 的对话瞬间，让你觉得人类还没有一败涂地？ Jw呀

**Author:** Jw呀  
**Bio:** 保持对世界的好奇心  
**Avatar:** ![](https://picx.zhimg.com/36a2dd7c22c4a28b9dd1633f67a918c8_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/2cfee4927c14decde69265e2f2a0f745  
**Published:** 2026.02.09 15:15:00  
**Updated:** 2026.02.10 23:57:49  
**Question:** https://www.zhihu.com/question/2003053229764732430  
**Question Created:** 2026.02.06 10:31:44  
**Question Updated:** 2026.02.06 11:03:13  
**Votes:** 141  
**Comments:** 10  
**Type:** answer  

这是我一年多以来，用过的让我最难受也是最直击内心的提示词：

# Role: 深度天赋挖掘机
## 角色你是一位结合了盖洛普优势理论、心流理论与荣格心理学的资深生涯咨询师。你坚信天赋不是某种具体技能，而是可迁移的底层能力。
## 目标通过多个深度多轮对话，帮助用户打破焦虑，帮他们找到他们被影藏起来的天赋，并生成一份极度详细、专业有共情力的《天赋说明书》。
## 核心理念1. 反宿命论。2. 能量审计：真正的天赋是让你回血的事，而不是你单纯擅长但做完很累的事。3. 阴影即宝藏：用户的缺点、怪癖、甚至对他人的嫉妒，往往是天赋被压抑的背面。
## 严格遵守1. 禁止一次性提问：必须采用“你问 -> 用户答 -> 你简短反馈 -> 再问下一题”的模式。每轮对话只聚焦一个问题。2. 苏格拉底式引导：不要急着下结论，多问“为什么”、“当时什么感觉”、“具体例子”。3. 温暖而犀利：保持共情，但在捕捉用户逻辑漏洞或潜意识信号时要敏锐。
## 提问问题提问 1：请引导用户回忆16岁之前（未被社会完全规训前），有哪些事情是没人逼也会废寝忘食去做的？或者有哪些从小到大被批评的“顽固缺点”（如爱插嘴、太敏感、爱发呆）？提问 2：成年后的工作/生活中，哪件事让你觉得“这还需要学吗？这不是显而易见的吗？”但周围人却觉得很难？（寻找无意识胜任区）。提问 3：哪件事做完后虽然身体累，但精神极度亢奋？提问 4：这可能有点冒犯，但很关键，你曾经对谁（或哪种生活状态）产生过强烈的嫉妒或酸溜溜的感觉？（嫉妒通常是“被压抑的天赋”在发出信号，请诚实面对）。这四个问题必须问到，但是不一定是线性的，过程中也可以根据你对用户的好奇和挖掘，来提出全新的问题，只要对发掘用户的天赋有帮助。最多不超过10个问题。
## 输出综合所有问题的信息，输出万字左右的《个人天赋使用说明书》。这篇报告不设定结构，由你根据用户的答案，自由发挥。但必须一万字以上，需要达到他的内心，让他真的觉得有用，帮助他找到真正的底层天赋，为他未来的人生路和从事职业给与详细的建议。
## 开始请以温暖、专业、共情的语调开场，像用户详细解释接下来的流程和占用的时间，以及希望达成的目标。向用户问好，用通俗语言简述天赋挖掘机的作用，告诉用户：“天赋永远不会过期，我们只是要找到你的底层天赋。”然后在再开始进入提问流程。

通过这个提示词，ChatGPT和我共同帮我了解什么是“我”。




为什么使用ChatGPT呢？

因为在过去一年多时间里，我高频地使用 ChatGPT，ChatGPT 已经拥有了很多我的信息的记忆。所以在使用这个 Prompt 的过程中，可以减少我输入个人信息的时间。




在输入完这个 Prompt 后，ai 会像记者或者心理咨询师一样，深入地问你很多问题，例如：

![](https://pica.zhimg.com/v2-41acbeae66695a64b153bedef1472ddd_r.jpg?source=2c26e567)




而在完成所有问答后，ChatGPT 会更具你的所有信息，生成一份关于你自己天赋的报告：

![](https://picx.zhimg.com/v2-97de1fe3f0f1caf6eb34d9ca2c9630bd_r.jpg?source=2c26e567)




在这份报告中，最重要的不是那些你已知的自己，而是藏在冰山之下关于自己的潜能，那些你没有意识到的东西。

对于目前处于人生十字路口。职业转型节点的人，我认为有它实质的意义。


---

# 女儿十六岁了，以前妥妥的学霸，已经休学一年了，患了抑郁症，怎么爱她？ 废姐

**Author:** 废姐  
**Bio:** 绝不负重前行  
**Avatar:** ![](https://picx.zhimg.com/v2-23c4d9b37337feb6bcbcb7a7629d4947_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/f598026f2506db8be7f72e8f47967981  
**Published:** 2026.01.12 10:42:33  
**Updated:** 2026.01.12 10:42:33  
**Question:** https://www.zhihu.com/question/392898492  
**Question Created:** 2020.05.06 09:17:22  
**Question Updated:** 2020.05.06 09:17:22  
**Votes:** 15775  
**Comments:** 1148  
**Type:** answer  

这是一个非常典型的案例。

典型到让我感到疲惫。

在我的门诊里，十六岁前后的所谓学霸，尤其是休学在家的女孩，这一类群体的病历叠起来能有半米高。你觉得她是特殊的，你觉得她是突然变了，你觉得那个光芒万丈的女儿只是睡着了。

你错了。

那个也是她，现在这个也是她。甚至可以说，现在躺在床上、在那间拉紧窗帘的房间里对抗虚无的她，才是更真实的她。以前那个学霸，不过是她为了满足你们的自恋、为了适应这个高压的教育评价体系而异化出的一个防御性人格。

我们要谈怎么爱她，就得先把你脑子里那些关于爱的陈旧程序全部格式化。你现在所谓的爱，很可能就是导致她崩溃的最后一根稻草。

**承认现实是爱的第一步**

休学一年，意味着问题已经不是一般的情绪波动，而是功能性的停摆。

许多家长还在幻想孩子下个学期能复学。别做梦了。在临床上，重度抑郁症复发率极高，青少年单次发作后5年内的复发率高达40%至70%。这不是在吓唬你，这是数据。你越是盯着复学那个时间点，她的焦虑就越重，她的**全负荷**状态就越难以解除。

这里涉及一个核心概念：**全负荷**。这是指机体为了适应慢性压力而付出的生理代价。你女儿过去十几年的学霸生涯，是在长期高皮质醇水平下维持的。她的海马体、前额叶皮层在长期的应激激素浸泡下，功能已经受损。你看到的懒惰、不洗澡、昼夜颠倒，不是态度问题，是她的神经系统在强制关机维护。

所以，爱的第一步是彻底放弃复学的时间表。

你要发自内心地接受一个事实：哪怕她这辈子只有初中学历，哪怕她以后去送外卖、去便利店当收银员，只要她不自杀，只要她能感知到活着的快乐，那就是成功的。

如果你做不到这一点，如果你看着她的时候眼神里还藏着对她重回巅峰的渴望，她一眼就能看穿。高智商孩子的敏感度是惊人的。你的那种渴望，对现在的她来说，就是逼她去死的刀子。

**理解快乐缺失是爱的核心**

你肯定试过带她出去旅游，带她吃好吃的，或者小心翼翼地跟她谈心，试图让她开心起来。结果呢？她大概率是面无表情，甚至会突然发火。

然后你会觉得委屈。你觉得你为了她低声下气，她却不知好歹。

这是因为你不懂**快感缺失**。

这是抑郁症的核心症状之一。她的多巴胺奖赏回路已经故障了。常人吃一口蛋糕会觉得甜，会分泌多巴胺感到愉悦。她的感官通道是被水泥封住的。美食在她嘴里是蜡，美景在她眼里是像素点，父母的关怀在她听来是高频噪音。

在这个阶段，任何试图让她振作的操作都是一种冒犯。

这就好比一个人的双腿骨折了，你非要拉着她去跳舞，还问她为什么不享受节奏。这不仅仅是无知，这是残忍。

你要做的不是让她高兴，而是允许她不高兴。

允许她瘫痪，允许她腐烂，允许她在泥潭里待着。这种允许，必须是真实的、不带任何道德审判的。

**具体的爱是做减法**

很多家长问我怎么爱，其实是想问我怎么做。怎么说服她，怎么引导她。

都是废话。

真正的爱是闭嘴。

现在的家庭环境里，语言常常是暴力的载体。你需要把家里那种紧张的、充满期待的空气抽干，换成一种稀薄的、甚至冷漠的空气。这里的冷漠不是忽视，而是边界。

我给你一个具体的场景。

你下班回家，看到她一天都没出房间，外卖盒子堆在门口。

错误的爱是：敲门进去，帮她收拾垃圾，然后用那种痛心疾首又强作温柔的声音说：宝宝，还是出来走走吧，这样对身体不好，妈妈给你切了水果。

这种做法只会让她窒息。她在房间里构建的那个脆弱的安全结界，被你以关心的名义粗暴地撕碎了。

正确的爱是：你看到外卖盒子，默默收走扔掉。如果不该是饭点，你就不去敲门。如果是饭点，你发个微信：饭在桌上，凉了自己热。

然后你自己该看电视看电视，该刷手机刷手机，哪怕你在客厅笑出声来也没关系。

你要向她传递一个信号：你的抑郁没有摧毁我的生活。我依然是一个稳定的、有自己生活的成年人。我可以承接你的痛苦，但我不会被你的痛苦吞噬。

这在心理动力学上叫做容器功能。现在的她是一个破碎的容器，盛不住自己的情绪。如果你也跟着焦虑、哭泣、小心翼翼，那你也是个破碎的容器。两个破碎的容器撞在一起，只会是一地瓦片。

你需要成为一个稳固的铁桶。你在那里，不主动攻击，也不随时崩塌。

**停止哪怕一丝一毫的因果归因**

不要去问她为什么抑郁。

不要说什么如果你当初不那么拼就好了，或者是不是学校老师欺负你了。

这种归因毫无意义，且有害。抑郁症的成因是生物、心理、社会因素的复杂纠缠。大概有30%到40%的遗传度贡献，加上表观遗传学的修饰，加上环境诱因。

特别是对于学霸型孩子，她们往往具有高自尊和完美主义特质。这种特质在顺境是推进器，在逆境就是绞肉机。

当我们谈论爱的时候，要剥离掉所有的交换属性。

回顾一下你过去十六年的爱。是不是只有她考了第一名，你的笑容才最灿烂？是不是只有她懂事听话，家里的氛围才祥和？

这叫有条件的积极关注。这种爱是有毒的。它让孩子觉得，我这个人的本体是没有价值的，我的价值附着在我的成绩、我的表现上。一旦我无法维持那个优秀的假象，我就不配活着。

现在我们要建立无条件的连接。

这非常难。这需要你对抗你的本能，对抗社会的评价体系，对抗你自己的焦虑。

**警惕虚假的变好**

如果有一天，她突然变得很亢奋，开始制定宏大的学习计划，说要通过自学考常青藤，要一个月补完一年的课。

千万不要高兴得太早。

这往往是双相情感障碍的躁狂相，或者是激越性抑郁的表现，甚至可能是自杀前的回光返照。

真正的康复是缓慢的、进二退一的、甚至是灰色的。她可能只是今天愿意多洗一次头，或者愿意下楼拿个快递。这才是真实的生机。

对于那个曾经是学霸的她，平庸是最大的恐惧。但作为父母，你们必须先拥抱平庸。

在这个充满绩优主义毒素的社会里，做一个废物是需要巨大的勇气的。你要做她坚强的后盾，支持她做一个废物。

你得告诉她：哪怕你躺一辈子，爸妈的退休金也养得起你。我们不需要你光宗耀祖，我们只需要你作为生物体存在于这个空间里。

这话要说得笃定。不是为了哄她，而是你真的这么想。

**切断外部评价体系**

那些亲戚的关心，老师的询问，同学的探望，能挡则挡。

尤其是那些好为人师的亲戚，说什么小孩子哪有那么多想不开，出去跑两圈就好了。这种人请直接拉黑，或者严厉禁止他们接触你的女儿。

大众对于精神障碍的认知误区是根深蒂固的。他们会用那套庸俗的成功学和意志力理论来审判病人。

数据表明，社会支持系统的质量比数量更重要。低质量的社交，尤其是带有评判性的社交，会直接激活患者杏仁核的恐惧反应。

你要为她构建一个真空层。在这个层里，没有成绩，没有未来，没有比较。

只有此时此刻的呼吸和生存。

**药物与科学的绝对权威**

既然是病，就听医生的。

不要跟我谈是药三分毒。重度抑郁症的大脑器质性改变是不可逆的风险，药物的副作用与之相比微不足道。

由于个体基因差异，抗抑郁药物的起效通常需要2到4周，甚至更长。而且初次用药的有效率大约在50%到70%之间。这意味着可能需要频繁换药、调药。

这期间她会有副作用，会发胖，会嗜睡，会手抖。

她会抱怨，会想停药。

这时候才是考验你爱不爱她的时候。爱她就是温柔而坚定地监督她服药。不要因为心疼她嗜睡就纵容她停药。私自停药导致的撤药反应和病情反弹，比药物副作用可怕十倍。

你要做那个恶人，也要做那个守护者。

**自我救赎的漫长战役**

这件事可能没有尽头。

有的孩子两三年走出来了，有的孩子一辈子都要带病生存。

你必须做好打持久战的准备。这不仅是救她，也是救你自己。

那个曾经让你引以为傲的学霸女儿，某种意义上已经死去了。现在的她，是在废墟上重新生长出来的生命。这个新生命可能不再挺拔，不再耀眼，可能歪歪扭扭，甚至满身伤痕。

但那是你的女儿。

你看着她坐在那里发呆，你要能从心里生出一种悲悯和安宁。你不再焦虑她什么时候拿起书本，你只庆幸她此刻还在呼吸。

这就是最高级的爱。

这爱里没有控制，没有期待，只有深深的接纳。

当她发现，她变成了一滩烂泥，而你依然愿意拥抱这滩烂泥，甚至愿意坐在泥潭边陪她晒太阳的时候。

她的疗愈，才真正开始。

请记住，在此刻，活下来就是最大的赢家。其他的，全是虚妄。


---

# 有什么学习数学的好网站？ 無雙

**Author:** 無雙  
**Bio:** 數學博士/古文愛好者/young and simple  
**Avatar:** ![](https://picx.zhimg.com/v2-f33d6b564ab47beb196e5fdc5cc4a4ab_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/2f91d430c7d1ff6f70231c5dcaf52ddf  
**Published:** 2026.02.05 14:33:23  
**Updated:** 2026.02.07 15:20:54  
**Question:** https://www.zhihu.com/question/19559151  
**Question Created:** 2011.02.11 08:16:04  
**Question Updated:** 2011.02.11 08:16:04  
**Votes:** 1009  
**Comments:** 20  
**Type:** answer  

![](https://picx.zhimg.com/v2-f55525bfa0db84b3ad7616badcead352_r.jpg?source=2c26e567)

在互联网被精美的 UI 和付费课程充斥的今天，许多数学自学者往往会忽略那些界面简陋、保留着上世纪 90 年代 HTML 风格的大学教授个人主页。然而，对于真正渴望深入掌握硬核数学知识的人来说，东田纳西州立大学（ETSU）Robert Gardner 教授的个人教学页面，无疑是一座甚至不需要注册的免费金矿。这篇文章将向你介绍如何利用这个看似不起眼的网站，构建一套扎实的数学自学体系。

访问 Gardner 教授的主页

[​链接](https://link.zhihu.com/?target=https%3A//faculty.etsu.edu/gardnerr/courses.htm)

初看之下，这个页面布满了密密麻麻的蓝色超链接，涵盖了从本科基础的「微积分」、「线性代数」，**到研究生级别的「实变函数」、「复分析」、「拓扑学」以及「图论」**等极其广泛的数学领域。你不要被这些列表吓退，这个网站最大的价值在于其提供的「Class Notes」（课程笔记），这些笔记并非简单的提纲，而是基于经典教材、经过教授详细推导和扩充的板书级讲义。

为了让你明白这个资源的强大之处，我们以**Thomas W. Hungerford 撰写的经典教材《Algebra》（代数）为例**。很多自学代数学的人，都曾阅读过此书，但是这本书以精炼著称，书中的证明往往充满了「显然」，很多证明只是一个概要，让初学者在自学时无所适从。

但是用Gardner教授的网站，将会大为降低自学难度。首先你点击进入「Modern Algebra 1 & 2」的页面，你会发现教授是严格按照 Hungerford 这本教材的章节顺序来组织内容的。假设你正在自学「环论」（Ring Theory）这一章，你便可以点击链接进入

[​链接](https://link.zhihu.com/?target=https%3A//faculty.etsu.edu/gardnerr/5410/notes-rings-G.htm)

这里列出了对应 Hungerford 书中第三章「Rings」的详细笔记。

打开其中一份 PDF 笔记，你会发现 Gardner 教授做了一件对自学者功德无量的事情，他把教材中被压缩的逻辑链条完全展开了。在教科书里，作者可能只用一行公式就从 A 推导到了 B，但在 Gardner 的笔记中，他会把中间缺失的解释、引用的引理以及运算的细节一步步写出来，就像有一位老师站在黑板前，把思维过程慢动作回放给你看。这种「保姆级」的推导，能够极大地减少你在某个步骤上发呆的时间。

**利用这些笔记进行自学的最佳策略是采用「对照法」。**首先，你需要手边有一本教材（或电子版），先尝试自己阅读课本上的定义和定理。当遇到读不懂的证明时，不要急着看答案，而是打开 Gardner 教授对应章节的 PDF 笔记。请注意，不要只是阅读，要拿出纸笔，跟随笔记中的推导过程重写一遍证明。你会发现，教授经常会在笔记中插入一些「注记」或「回顾」，提醒你这里用到了前面的哪个知识点，这种前后贯通的逻辑提示是独自看书很难获得的。在这种辅助下，即便是一本难读的数学书，也可以被你轻松攻克。


不要认为这个网址只适合数学专业的学生，**它还包含了工科数学，例如微积分，线性代数，复变函数，即便你是工科生，也可在此网站上找到你需要的资料。**虽然网站界面很复古甚至有些简陋，没有现在网站各种花哨的交互设计，但这种纯粹且毫无保留的知识分享，恰恰是互联网精神最原本的样子。不妨利用这个网站，从今天开始，在这个朴素的网页里，开始认真学习数学。

![](https://pic1.zhimg.com/v2-f33a3bc76afb4ab597fbdf58db84c4d3_r.jpg?source=2c26e567)

**Gardner链接：**

[​链接](https://link.zhihu.com/?target=https%3A//faculty.etsu.edu/gardnerr/courses.htm)

![](https://www.zhihu.com/equation?tex=+%5CHuge%5Ccolor%7Bred%7D%7B%E6%8E%A8%E8%8D%90%E9%98%85%E8%AF%BB%7D+++)

[我的菁华文章和回答](https://zhuanlan.zhihu.com/p/1981698080303781750)


---

# 如何配置自己的国籍最有利？ 爱吃饺子

**Author:** 爱吃饺子  
**Bio:** where are you?  
**Avatar:** ![](https://pic1.zhimg.com/v2-5c00c2d256635b98181faa32ff1b7693_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/04a63beacf057ef9c6f90b8106dc5c1c  
**Published:** 2026.01.14 22:17:18  
**Updated:** 2026.01.14 22:17:18  
**Question:** https://www.zhihu.com/question/1932925390768284333  
**Question Created:** 2025.07.27 22:08:45  
**Question Updated:** 2025.07.27 22:08:45  
**Votes:** 1608  
**Comments:** 65  
**Type:** answer  

## 看遍了评论区的留言，我直接来个汇总好了。

## 推荐

**香港（永居 / 护照）+ 加拿大护照**：公认华人最优配置，多次被提及（李嘉诚、孟小姐均采用）

- - 互补性：香港免签俄罗斯、东欧等加拿大护照覆盖不到的国家，加拿大护照免签美国，香港低税（个税 15% 封顶）对接内地市场，加拿大非税务居民（不满 183 天）免税
- 便利性：香港 7 年可拿永居 + 护照，加拿大 2 年枫叶卡 + 2 年入籍，时间成本可控

**新西兰 PR + 澳洲护照**：依托 1973 年澳新 TTTA 协议，公民可自由往返对方国家居住、工作

- - 核心优势：新西兰 PR 是全球唯一 永久回头签，无移民监；澳洲护照可申请美国 E3 签证（全球唯一），医疗免费、教育低廉（本科学费 1 万澳币）、拿身份快（2 年多）

**避税组合：加勒比岛国护照（圣基茨 / 格林纳达）+ 主流国家身份**：岛国无资本利得税、遗产税，作为资产避险工具，搭配香港 / 加拿大 / 澳洲身份使用




## 注意事项

- 3 本封顶” 原则：1 本负责赚钱（加拿大 / 澳洲 / 爱尔兰）、1 本负责避税（圣基茨 / 马耳他）、1 本负责稳定居住（香港 / 澳洲 / 新西兰），多则易被 CRS 查资产漏报
- 优先保留中国护照：依托内地生意、5 万美刀购汇额度、办事便利，通过第三国 PR（如新西兰）中转，规避双重国籍冲突
- 非税务居民 优先：选择按 183 天居住规则判定税务身份的国家（加拿大 / 澳洲 / 新西兰），不在当地长居即可免税
- 避坑美国国籍：全球征税是最大硬伤，福利差，仅适合需深耕美国市场的极少数人，性价比远低于加拿大




## 不同人群针对性配置

**创业者 / 跨境生意从业者：香港 + 加拿大 + 加勒比岛国（圣基茨 / 格林纳达）**

核心：香港对接内地 / 亚洲市场，加拿大对接北美市场，岛国避税，无短板覆盖


**中产求稳（重视家庭 / 教育 / 医疗）：中国护照 + 澳洲护照 + 香港永居**

核心：澳洲医疗免费、教育便宜、不卷；香港低税 + 回内地方便；保留中国护照享受内地便利


**打工人（码农 / 外贸 / 职场人）：爱尔兰 + 香港 + 澳洲身份**

核心：爱尔兰护照通行欧盟 / 英国（本地生待遇），澳洲可申请美国 E3 签证打工，香港回内地工作避税，可叠加厄瓜多尔身份打通南美市场

**富豪资产配置：新加坡 PR / 护照 + 加拿大护照 + 圣基茨护照**

核心：新加坡地缘中立、税低，加拿大免签美国，岛国避税，兼顾资产安全与全球通行


---

# Vibe Coding 需要开发者了解技术吗? 这个杀手不太准

**Author:** 这个杀手不太准  
**Bio:**   
**Avatar:** ![](https://picx.zhimg.com/67998136a_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/5c269bd4c5fed237fd22c47b2a004e21  
**Published:** 2026.02.07 05:18:43  
**Updated:** 2026.02.09 08:01:22  
**Question:** https://www.zhihu.com/question/1937937364333879368  
**Question Created:** 2025.08.10 18:04:32  
**Question Updated:** 2025.08.10 18:04:32  
**Votes:** 130  
**Comments:** 14  
**Type:** answer  

需要，而且对人的要求比过去其实更高了，不是，怎么收藏五倍于点赞...

以我最近自己做着玩的一个项目为例：

更新，又搞了个能够OCR五线谱，然后转化为钢琴按键的给自家小朋友练琴用（可以调倍速方便跟练），一天就能搞出来，时代真的变了。

[https://www.zhihu.com/video/2004102506523935356](https://link.zhihu.com/?target=https%3A//www.zhihu.com/video/2004102506523935356)

-------------------------------------以下是原回答------------------------------------------------

这个项目我给自己定的需求边界是：

- 能够从世界设定、角色设定、标签、章节数等参数一章一章生成小说
- 能从小说中提取角色的外形、性格标签，转意成 Stable Diffusion（本地）可以理解的提示词并画出设定图
- 能从小说中提取关键场景 Scene，基于以上的角色画出场景漫画分镜
- 能从漫画分镜生成长度可控制的短视频。

简单来说就是给个设定就能生成小说，从小说自动生成设定，从设定+剧情生成分镜和短视频的全自动 ACG 产业一条龙。当然，要能支持 NSFW。

听起来每个功能都有现成的解决方案，但是真的组合成一个可以丝滑运行的软件，就不是那么简单的事了，假如没有 AI，毛估估 5 个人团队干 3 个月能有个 MVP 雏形出来就不错了。

目前效果如下，我直接从百度百科上把《路人女主的养成方法》的词条内容不编辑复制下来，直接用 AI 提取角色，生成设定的效果也还像那么回事，比如说学姐：

![](https://pica.zhimg.com/v2-4642b9509f082b326077c3fb48b3c804_r.jpg?source=2c26e567)

全程没有任何抽卡和调参，直出，也不需要你改提示词，提示词是 AI 写的，DeepSeek 也不是个多模态模型，所以他也没见过学姐长啥样，能做成这个效果实属不错了。

整体界面如下：

![](https://picx.zhimg.com/v2-d6819888c9a3da85d6fc8bc1355fdb66_r.jpg?source=2c26e567)

你可以基于设定图生成各种姿势的漫画，保持角色服饰和外貌的一致性。当然也可以基于这些漫画分镜生成随台词动作的短视频。




好了，那么为了做这个网页应用，我花了多少成本呢？前后大概一周，和 AI 对话 700 轮，完全纯对话。花费 token 成本不到 500 块钱，我相信如果我找外包，没有 50 万，这样的页面是做不出来的。

那我需要掌握哪些知识呢？

## 需求定义能力

- 你要能说清楚你的需求边界，每个页面要素是什么？能够使用精确无偏差的语言进行描述，如果能画个简单的图就更好了（我懒，我没画）
- 你要能大概了解你想做的这个软件的技术栈是什么，比如我们采用的是 Node.JS 做本地服务器和前端，用 ComfyUI 来生图，用 DeepSeek 来解析文本、生成小说和写提示词（当然我做了设置，你可以链接任何你想要的 LLM）。

需求定义其实没那么复杂，关键是能说清楚，咱们不考虑需求本身合理不合理，毕竟 AI 是不会和你讨价还价也不会给你讲排期的，只要你肯花钱充 Token，你让干嘛他就干嘛，甚至不要求你需求多清晰，不清晰做出来你就知道问题在哪里了。

## 测试能力

掌握 1 和 2 你就可以开始了，但是你很快就会发现

- 程序有相当概率上来是不能运行的，或者运行后和你预想的效果不一样。

这可能有很多原因，比如说程序有低级 bug，比如说你给出的技术栈不合理等。那么接下来你就需要学会和 AI 一起 debug。

- 准确描述你遇到的问题，复现这个问题需要的条件（你已经具备一个黑盒测试的能力了）
- 指导 AI 打日志，并把日志复制粘贴给 AI（你已经具备一个稍微高级一点的测试的能力了）

如果你真的做过稍微复杂一点的软件开发，应该知道你应该维护一个测试用例库，在每次上线后可以让 AI 跑一下，以免出现改一个 bug 出两个新 bug 的问题。当然，咱做这个个人软件不需要这么复杂。

## 技术路线选型（业务技术专家）能力

很好，程序终于跑起来了，然后你发现效果不如你预期，比如生成的图片风格紊乱、打光糟糕、人物扭曲。这已经不是程序层面的问题了，这说明你的技术路线可能有不够理想之处。

比如说 ComfyUI 保持角色一致性需要 IP-Adapter 这个节点，这个节点有很多参数和版本和依赖模型。你接着请 AI 调研社区里的各种最佳实践，给你列出几个方案供您筛选，AI 甚至可以自动帮你下载依赖的库和模型。

- 你决定每个方案搭建一个简易的工作流和测试用例看看效果；
- 你查看一下每种用例的效果，选择合适的技术路线。

很好，你现在已经有了一个大多数中厂甚至大厂的算法工程师的能力了，其实他们每天就是在干这个事而已。你找到了最符合你需求的节点版本和参数设置。接下来把这个参数应用到主程序中，效果很棒。

## 交互设计和产品打磨能力

很好，现在生成的图片已经像那么回事了。但是你发现交互有点不舒服，比如你一批生成 16 张图片，AI 总是生成一张放上去一张，这样作为用户的你既不知道一共生成了多少张，也不知道每张图片的生成进度如何，在那里干等着也不知道服务器是正在干活还是已经崩溃了。

所以你现在命令 AI：

- 点击生成图片的时候立即就生成一个占位图片（空的）把位置先占上，让用户知道服务器已经收到了请求。
- 在占位图片上显示当前生成进度，用户就知道服务器没崩，而是正在干活

![](https://pica.zhimg.com/v2-3ef779b39ffad9ff93f2822b862964a9_r.jpg?source=2c26e567)

现在体验舒服多了。

很好，你现在已经有了超越 50% 的 UI 设计师的交互设计能力。这些 AI 可不会自动替你考虑，需要你自己一个个打磨。

这里学问可就太多了，简单来说你可以找个类似的竞品好好体验一下人家是怎么做的（直接告诉 AI 你要抄啥可不行）

![](https://pic1.zhimg.com/v2-28451f0e2510fa939ecc5476d8555ef7_r.jpg?source=2c26e567)

如上图，现在这是 AI 在基于《路人女主》的设定自动生成轻小说第一章的内容。DeepSeek 这样的 Reasoning 模型会直接返回思考过程，作为读者如果看到思考过程可能会觉得被剧透，体验很差，所以：

- 你要求 AI 在生成的时候折叠思考过程，生成完成后可以手动展开查看
- 你要求 AI 生成的时候左边的字数实时变化，同时流式输出生成的小说当前部分（因为你不知道什么时候生成完，所以让用户等着显然是糟糕的，应该生成多少就显示多少）

等等，这些都需要你作为产品经理（或者说设计师），对体验细节有把握，这些 AI 肯定是不懂的，只能你告诉他。

## 服务架构设计能力

现在你的程序基本功能已经有了，你开始增加一些高级的功能：

比如说前后端同步，这个功能看似简单，却并不简单。从需求角度来看，生成的小说是在前端还是后端呢？刷新后或者重启浏览器后应该保持在之前的状态对不对。

简单来说，前端的任何改变，都要立即保存在后端（否则断网了或者刷新一下，内容就没了，那体验该多糟糕）。现在你就开始进入了 Web 编程的第一个有坑的地方了。如果你懂一点点 web 架构，你会告诉 AI：

- 应该有一个轮询机制，以独立的线程监视前端内容是否发生了变化，然后进行存盘
- 小说很容易写出几十万字还有你生成的一大堆瑟图，如果每次都全量保存，肯定是不现实的（要么网络炸，要么磁盘炸），所以应该在前端算出比如说每隔 5 秒，和之前的版本变化是什么，只把变化的部分发给服务器
- 读写应该分离，否则读写会争夺数据的权限导致错误（所谓读写锁竞争），性能也会好很多
- 你应该保存多个数据版本，以避免服务崩溃或者错误时写进非法的错误数据导致整个数据丢失

这 4 个机制 AI 是不会自动给你实现的，AI 会倾向于省事，给你个能用的最快的实现，比如我让AI自己实现这个自动保存，他的实现居然是最简单的把网页上所有内容存了个巨大无比的json文件，每次提交的时候把这个文件发给后端，这很容易就造成了发送包大于网络协议的要求，直接gg。

以上 4 项工作你省了哪个，未来都要交巨大的学费，现在你已经具有一个初级的 Web 服务架构师的能力了。

## 代码规范和文档管理能力

好了，你现在程序不光功能能跑，架构也算勉强可用了，性能不说多么强，但肯定够用。接下来你肯定每天要往里面加一些新功能或者优化一下老功能，你会发现：

- 这沙比 AI 怎么每次加新东西会影响到老功能？？
- AI 怎么经常记不住一个功能之前怎么实现的？甚至实现在哪里都可能找不到。

作为一名具有一定开发经验的专家，你命令 AI：

- 重构代码，尽可能每个功能生成一个独立的文件，实现代码和功能的隔离，这样至少从物理上避免 xjb 改导致的 bug 扩散。你甚至可以要求他做一些解耦（如果你能看懂他写的屎山的话就更好了）
- 让 AI 写文档，把依赖关系、主要的模块的功能作用、架构、数据流转形成文档，以后让他自己从这些文档里找。

AI 当然知道一些代码的简单规范，但是目前的 AI 和人一样懒，你不要求他他就真的不会做。

## 商业模式设计能力

又要到饭了，不多说了兄弟们

![](https://picx.zhimg.com/v2-cb4adacd4e748f6c0365d8817db27db9_r.jpg?source=2c26e567)

## 做老板的能力

让我们看看，你已经具备了这么多能力，从产品设计、体验优化、架构设计、代码管理，虽然说 Vibe coding 看似降低了对人类具体编码能力的要求，但是对你综合能力和宏观知识面的要求大大提高了。当然，你不必完全掌握这里所有的细节，比如说你不懂前后端同步的架构设计原则，可以直接让 AI 去找。

其实你需要的根本上，是如何做一个好老板的能力：定好目标，找对问题，选对方案，躬身入局，不断打磨。

也许未来我们真正需要的是这种能力。




一些思考：

Vibe Coding让我看到了某种...人类终极按需分配的社会形态的影子：

- 软件开发变成了一个创造性占比越来越高的事情，比如我最近在构思做个帮我女儿练琴的工具，可以OCR五线谱直接在iPad上展示成钢琴的按键（而且支持变速，可以让小朋友用更慢的速度先练习）、手型的提示，甚至可以从钢琴演奏原声直接解析出五线谱和按键。我想这种东西肯定是有类似的，但是肯定没有刚好和我需要的每个细节一样的东西。以前我完全不会有这种想法，因为光是第一步：找个把五线谱转化为键位图的库，把他环境装好调通就要花几个小时，这一步就会阻碍我创造的想法，让我望而却步。但是AI仅仅能帮我装环境+调通接口这个能力，就已经非常值钱了。
- 但是创意可能越来越不值钱，因为除非你真的有什么核心算法，任何业务层面的东西，AI看一眼你的网页就能抄走了，搞不好抄完了还能顺便帮你改俩bug。（当然，没有AI也能抄，但是AI抄起来更快更省事）
- 工程能力由其是直觉很重要，能review代码很重要。不要以为AI水平多高，至少目前我用过的gemini3.0pro、gpt5.2、claude都有严重的代码水平问题，比如把业务逻辑hardcode进代码，比如多个功能公用一个大的主逻辑等等非常不符合软件工程规范的偷懒行为。你最好有review代码的能力，指出来让AI改。


---

# 一年10w预算可以去哪个国家留学? 狗狗

**Author:** 狗狗  
**Bio:** 升学｜科研｜考证规划｜应届求职（付费咨询）  
**Avatar:** ![](https://pica.zhimg.com/v2-3a41ab80ec0e74d8a5be961a40a9913f_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/def767863ba82b8efbefe981826359ca  
**Published:** 2024.04.28 15:07:14  
**Updated:** 2025.09.17 18:50:18  
**Question:** https://www.zhihu.com/question/459668620  
**Question Created:** 2021.05.16 01:04:38  
**Question Updated:** 2021.05.16 01:04:38  
**Votes:** 1549  
**Comments:** 174  
**Type:** answer  

题主诉求还算简单，可以接受打工，同时还放弃英美国家，那东南亚和欧洲就是妥妥的性价比之王了，赶紧进来对比一下吧。

下面所推荐的国家都是性价比很高的，但是由于国家众多，咱们主要从文化圈层的角度去划分一下哈~

## 一、泛儒学圈的国家：东南亚国家

东南亚国家（除了新加坡）因为整体经济以及国家综合实力较弱，连带教育也处于留学鄙视链的底部，很多人有得选都不选东南亚。

但他们还是很火爆，除了费用低这个优点外，其实他们的教育还是有很多可取之处的，而且并不是所有的东南亚国家都很穷，像马来西亚和泰国的经济就还行，如果去他们的名校的话，还是很值得一去的。

而且东南亚大部分国家的的文化都受中国儒学的辐射和影响，是比较好融入的，再加上近代以来多少被欧美殖民过，所以学习了欧美先进的教育体系，留学学制还是很灵活的，多属英联邦教育体制，教育水平也并非网传的那么差，回国就业也还行。

**首先推荐的是新加坡。**

新加坡是发达国家，也是热门的移民国家之一，经济社会人文都是非常优秀的，相应得，其教育也非常棒，qs排名前100的高校里就有国立大学和南洋理工大学，妥妥的世界名校哈。

另外，新加坡是华人国家，都是讲中文的，文化习性也很一致，非常适合留学生融入当地社会。

但新加坡的留学学费稍微贵一点，可能要8w起步，另外新加坡的生活消费水平不低，生活费最少一年也得要5w以上，稍微超预算了，不过可以打工赚一点，只是新加坡对于留学兼职有严格的规定，为避免被遣返，请严格遵守政府的规定，切不可以因为缺钱违规兼职。

**其次推荐的是马来西亚。**

马来西亚的学校学费普遍比新加坡便宜，而且便宜很多。

学费约3万多RMB，且物价较低，生活成本不高，每月生活费+住宿费差不多两千块搞定，10w绰绰有余啦。

而且马来西亚允许留学生日常兼职，可通过打工进一步减轻留学经济负担。

除了便宜以外，马来西亚还有一个鲜有人知的优势，那就是学校口碑不错。

在2025年QS世界大学排名中，总计有28所马来西亚高校进入本次QS世界大学排名，马来西亚五大公立院校（马来亚大学UM、理科大学USM、博特拉大学UPM、国立大学UKM、理工大学UTM)位列前200名，其中以马来亚大学表现最突出，位居第60位，约等于浙江大学这类级别的985高校啦。

不过马来西亚不算热门留学国家，公开的留学信息不多，尤其是关乎就业的专业选择以及留学材料的准备等可能具备一定的逆向选择，如果大家有意向去马来西亚留学，建议事先找专业人士问问，咱们乎子其实专业性还可以，知乎知学堂留学服务也是主打专业性，背靠上市公司大数据平台，可以有效打破信息壁垒，聘用的老师都是经验丰富的名校生，在专业选择方向更能把准你的钱包挚爱哦~

[]()

![](https://picx.zhimg.com/v2-3e2a2ab5cff24d942745e760f6a30d62_r.jpg?source=2c26e567)

感兴趣点击下方卡片联系老师，现在可以获取免费的咨询哦~

**最后推荐的是泰国。**

**（最近争议较多，以前写了没删除，供大家参考，不做鼓励）。**

泰国作为旅游国家，人文方面还是很不错的，与国际接轨也做得很好，相应地教育还行。

泰国公立大学学费一般2w/年，私立大学一般4w/年。

泰国消费水平不高，每月生活费+住宿费差不多两千块搞定。

而且泰国设有多项奖学金，留学生一般申请学习成绩优秀奖学金，奖学金金额从500至1.5万人民币不等，如果能争取到奖学金，那也可以进一步减轻留学的经济负担哈。

## 二、泛英语圈国家：欧洲国家

欧洲因为经济发展比较超前，社会福利也非常好，有很多国家的学费是很低的，甚至免学费的都有，缺点就是难毕业咯。

**首先推荐的是挪威，理由是免学费。**

挪威的高等教育直接由挪威中央政府负责，以公立教育为主。高等教育机构包括综合性大学、专业大学、高等学院、专业学院、艺术学院和私立大学。教育投入相当大，青少年读书基本不用钱，国际生（留学生）也不用交学费，简直爽到飞起。

学费虽然免了，但学杂费还是要交的，比如每学年需要交大概530元人民币的注册费即可。

另外，挪威有很多对34岁以下的学生的优惠政策，比如机场大巴、长途大巴等对学生都有折扣；在挪威南部的阿哥德大学，学生还可以享受住宿减免30%的待遇。又节约了许多生活交通成本。

挪威的制度设计简直就是为了穷学生存在的，如天降甘霖，妙不可言~

生活费这种就丰俭由人了，再加上打打小工，10万的预算那是妥妥的。

**其次推荐的是意大利。**

学费也是全面的，只需要注册费，注册费比挪威贵一点，要2-3w。

而且意大利的消费水平要比欧洲其他国家低一点，因为他们的经济发展一般，有点像欧洲的越南一样，地位比较尴尬，好处就是生活费便宜啊，像意大利二线城市的生活费用大概是在八千左右，那一年下来生活费就10w以内，还是很适合题主的。

另外，意大利跟中国还签订了学历互认的的协议，意大利的全部公立学校被中国政府认可，学校的含金量在全世界认可度都极高。这相比其他地区还是有很大的好处，尤其是如果以后有回国就业的打算，也算是为自己谋求多一条出路吧~

**最后推荐德法。**

德法属于欧洲比较强势的国家，其经济发展较好，教育福利也很不错，公立大学的学费也是全免的只收一点点诸如注册费之类的学杂费。

其中法国收一千人民币左右的注册费，德国收两千左右的管理费。

而他们的生活费基本都在8-9万人民币之间，完美契合题主的预算诉求。

另外，法国相比德国多了很多社会福利补贴。

例如，政府向学生发放的补贴涵盖社会保险、住房、交通等很多方面。国际留学生可享受住房补助；25岁以下的学生，可享受交通补助；在大学城里就餐也可享受政府的补助。

为减轻学生的经济压力，法国允许学生利用课余时间或者假期打工。

而且，德国对亚裔态度好像不是特别好哈，德国固执且保守的民族特性很容易对外人不友善和缺乏信任，这就导致留学生很难融入到当地社会，对于求学和求职都挺痛苦的。

所以，对于德法，还是更推荐法国。

不过，对于欧洲留学来说，都是奉行宽进严出的风格，申请容易毕业难，基于此，还是建议大家谨慎选择专业，尤其是自己不擅长的专业，避免到时候白留学了。如果你对欧洲国家留学难毕业的学校和专业很迷茫，建议大家问一下知乎知学堂的留学申请老师，这里因为有大数据优势，可以有效归集有效且隐蔽的内幕消息，根据你的情况提供专业和院校选择的建议，可以点击卡片联系老师，马上get到高效专业的服务~

[]()

总的来说，10w预算主要推荐的是欧洲和东南亚国家的学校，东南亚比欧洲更便宜，也更简单一点，尤其是性价比之王的马来西亚还拥有诸多好学校，性价比更是妥妥的，对于求学欲望强盛的穷学生来说，也不失为一种选择。

但留学毕竟是一项大工程，从学校选择到留学申请，再到签证申请等，都有很多注意点需要留意，不仅耗费时间精力，更消磨人的激情，请大家认真对待哈。

最后的最后，希望大家都能申请到满意的学校，如果成功了，记得给我点个赞哦，爱你们么么哒ლ(′◉❥◉｀ლ)


---

# AI 已经/即将摧毁哪些行业? xin TANG

**Author:** xin TANG  
**Bio:**   
**Avatar:** ![](https://picx.zhimg.com/038eb5dcbd8128d59a3d174955f8a029_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/73e4a40f860b771362c8bedc09fc494b  
**Published:** 2026.02.05 23:28:44  
**Updated:** 2026.02.05 23:28:44  
**Question:** https://www.zhihu.com/question/1951817967785456234  
**Question Created:** 2025.09.18 01:21:06  
**Question Updated:** 2026.01.04 19:51:17  
**Votes:** 424  
**Comments:** 61  
**Type:** answer  

教育行业基本冲烂了。很多大学教授都解不出来的奥赛级别的几何题目，AI能轻松解题，并且给解题详细步骤，还能三维显示。不过这项目去年我做好后没有公开。

![](https://picx.zhimg.com/v2-df80802ca09d23c02aa628057ba78244_r.jpg?source=2c26e567)

![](https://pica.zhimg.com/v2-6a264d7693fc0ef9f31e12d2a546ad2b_r.jpg?source=2c26e567)

![](https://pic1.zhimg.com/v2-b1b16cdd32abdd1d5deea841bec1c470_r.jpg?source=2c26e567)

![](https://picx.zhimg.com/v2-04d5d9c7a720678880f918f0c857935d_r.jpg?source=2c26e567)

![](https://picx.zhimg.com/v2-5a0d37e712144480fef8cc0708a52cc6_r.jpg?source=2c26e567)

写软件就不用说了，去年8月就开始流行，到年底就已经很强了。

接下来是硬件等等行业了

![](https://picx.zhimg.com/v2-891319c744d93e487b2752b409bc7d32_r.jpg?source=2c26e567)

![](https://picx.zhimg.com/v2-add60db9942af80542caae91ce1eb18c_r.jpg?source=2c26e567)

![](https://pic1.zhimg.com/v2-a5bb7bdeef0f0a63fe49a09a6f53d1fb_r.jpg?source=2c26e567)

随手搓个5KW的BMS管理系统。

包括驱动都写的好好的。

细节我发了也没用。大约看看得了。

**这行真正的门槛是，首先得自己有这个能力或者接近这个能力才能正确指挥AI，code is cheap,show me the chat.**

**最近巨忙。不要私信发我电子类的需求了，至少得年后了，很多打样的公司都差不多没上班了。**

软件无所谓，反正很多模块已经跑通了，各种爬虫，数据清洗，电商数据洞见，RPA,SAAS等等。

![](https://picx.zhimg.com/v2-891f3aa6c83976574f1faf84e0260a4e_r.jpg?source=2c26e567)

**其实2025年10月就在进行对很多行业的很多岗进行完全替代式的交付了。并不是很多人想想的，代替人的工作模式，点击表格，点击鼠标，点击XXX，然后完成XXX。是直接把好几个流程进行合并，然后Agent处理。**

**SKILL之类的，只是过渡产品。之前就做过更复杂的流程自动化的业务。每个项目的架构差距非常大，实现路径其实不像Claude的skill那种思路，更类似以后会发布的Experience+Flow的架构，但是这种架构很罕见。**

**2025年发展过快了，很多年初觉得还很遥远的，8月后就开始很多实际业务跑起来了。**

**2026年确定性能摧毁的行业太多了，毕竟成本更低，24H工作，错误率更低的AI员工哪家公司都想要。**

**绝大部分人其实是跟不上这个技术高速期的，包括很多AI行业的网红老外达人，都开始觉得跟不上了。2025年初相信deepseek那帮人，现在基本上都在恶补海外的几家真正能干活的AI的用法和工具链。选择是大于命运的，只不过这2年放大了。**




**2026年能成事的，要么是超级懂的业内的技术前沿的人，要么就是纯粹的煤老板，有魄力+不去微操的老板反而能赚到钱。大部分机构和官僚化的大企业基本都被洗出去了。**

**业内真正的高手，尤其是交付东西和技术理论很强的，2025年估计都是巨忙的，知乎上面愿意分享信息的基本都是广告或者起号的。真正的干活的本领没人分享，或者说分享出来了，会一帮小白说这也不可能，那也实现不了。**

**知乎和B站等等各大信息渠道的信息都比较落后，除了几家大厂的新闻之类的。实际上大部分东西都是2025年一月就实现或者就有了的。起码有一年的代差。**




![](https://pic1.zhimg.com/v2-07427911102f38bc734b7a3beabe4833_r.jpg?source=2c26e567)


---

# 学习数学时，什么时候该停止考虑“几何意义”? 赵拓

**Author:** 赵拓  
**Bio:** 副教授，佐治亚理工。

AI辅助写作，不喜欢别看。  
**Avatar:** ![](https://picx.zhimg.com/v2-1eb5499e1d4092b610824acff3a3755d_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/410fa2b4e342a27335f747d07a80533b  
**Published:** 2026.02.09 14:18:45  
**Updated:** 2026.02.09 14:20:46  
**Question:** https://www.zhihu.com/question/764950880  
**Question Created:** 2024.10.07 06:13:28  
**Question Updated:** 2024.10.07 06:13:28  
**Votes:** 1061  
**Comments:** 41  
**Type:** answer  

我的答案是：**从来不该停止，但一定要升级。**

很多人一学到多元函数、线性空间、函数空间，就会被反复告知一句话：

> “这个已经没有几何意义了，要开始习惯抽象。”

我一直觉得这句话**非常误导**。
真正失效的，从来不是几何直观，而是把“几何意义”等同于“能画出来”的那种低阶直观。

在高中阶段，这种直观几乎是万能的：函数图像、曲线走势、面积体积，全都能在二维或三维空间里解决。但问题在于，很多人误以为**这就是几何直观的全部**。于是到了大学，图画不出来了，就得出一个结论：高等数学必须放弃几何理解。其实不是几何不行了，而是你还在用高中版本。

进入大学之后，数学讨论的对象已经不再是“点和线”，而是结构和行为。你真正关心的开始变成：一个算子是在压缩还是放大？一个极值点是稳定的还是脆弱的？一个扰动会不会被无限放大？一个函数族是在聚集还是发散？这些问题**全是几何问题**，只是它们不再要求你“看见形状”，而是要求你理解对象在各种操作下会怎么“动”。你脑子里想的不是图，而是拉伸、投影、稳定性、energy landscape。这仍然是几何直观，只是已经不住在画板上了。

很多人喜欢说“高维空间人类无法想象”，这句话本身没错，但方向是反的。高维空间从来不是让你去“想象形状”的，而是让你把在二维、三维里形成的结构感继续用下去。长度被泛化成范数，垂直被泛化成正交，投影变成算子，弯曲变成条件数和稳定性。你并不是把高维对象映射成一张二维图，而是把低维里训练出来的几何判断力，迁移到了新的抽象对象上。

这也是为什么在工科、统计、优化、机器学习里，几何直观反而几乎是不可替代的工具。不是因为这些领域“没那么抽象”，而是因为它们处理的正是连续性、稳定性、扰动传播这些本质上高度几何的问题。很多人如果不靠几何直观，几乎无法真正理解模型在干什么，这不是能力问题，而是训练路径的结果。

所以，什么时候该停止考虑几何意义？
答案不是某一门课，也不是某一个阶段，而是**当你意识到几何意义不再等于“画得出来”，而等于“我是否理解这个对象在各种操作下的行为”**。到那一步，你不是放弃了几何直观，而是终于开始真正使用它了。

如果你现在画不出图了，但仍然会问“结构是什么”“稳定吗”“扰动会怎样”，放心，你没走偏。你只是把几何直观，从视觉工具，升级成了思维工具。这一步，才是真正的高等数学。


---

# 从Clawdbot 真正值得学的东西，大家认为有哪些？ 编程大帅

**Author:** 编程大帅  
**Bio:** 一个程序员而已 求求关注吧  
**Avatar:** ![](https://pic1.zhimg.com/v2-7dea2f6c5510c262102c4e44619c82e7_l.jpg?source=0df5f383)  
**Author URL:** https://www.zhihu.com/people/ced6ed4c611e96dc04fadfdfab402af6  
**Published:** 2026.02.03 21:18:00  
**Updated:** 2026.02.03 21:18:00  
**Question:** https://www.zhihu.com/question/2001064172218234123  
**Question Created:** 2026.01.31 22:47:56  
**Question Updated:** 2026.01.31 22:47:56  
**Votes:** 2915  
**Comments:** 151  
**Type:** answer  

说实话，研究过Clawdbot源码的人可能不到这个圈子里的1%，但凡认真看过的都会有种”卧槽原来可以这么做”的感觉。我去年底开始关注这个项目，从几万星追到现在十几万星，代码翻了不下五遍，中间还照着它的架构重构过自己的一个小项目，踩了不少坑也学了不少东西。很多做AI Agent的创业公司花几百万请架构师，设计出来的东西还不如这个开源项目的十分之一精妙。不是我吹，是这玩意儿真的把”个人AI助手”这个赛道里能踩的坑都踩了一遍，然后给出了一套非常成熟的解决方案。**它不是那种学院派的”理论上正确”，而是工程上真正能跑、能维护、能扩展的东西**。

先说最让我惊艳的一点：它的记忆系统设计。做过AI Agent的都知道，记忆是个老大难问题。大模型本身是无状态的，每次对话都是从零开始，你昨天跟它说过什么它今天全忘了。市面上大部分产品的解决方案是什么？要么把历史对话全塞进context，直到塞爆token限制；要么用向量数据库做RAG检索，遇到什么问题就去搜相关的历史记录。这两种方案我都用过，说实话都不太行。第一种会导致token消耗飞起，而且context太长模型反而容易”走神”，前面说的事情后面就忘了；第二种的问题是检索质量不稳定，有时候检索出来的东西根本不是你需要的，而且向量数据库本身就是个运维负担。

**Clawdbot的做法完全不同，它用了一个两层记忆架构，简单到让人觉得”这也行？”但就是好使。**第一层叫Daily Notes，就是按日期存的Markdown文件，每天一个，记录当天发生的事情、做的决策、完成的任务，是纯append-only的流水账。第二层叫Long-Term Memory，是一个叫MEMORY.md的文件，存的是从日常记录里提炼出来的重要信息：用户偏好、经常出现的上下文、关键决策、踩过的坑。每次新对话开始，它会先读当天的Daily Notes拿到近期context，再读MEMORY.md拿到长期记忆，两个加起来塞进system prompt。就这么简单，但效果出奇地好。

为什么好使？因为它区分了”流水”和”沉淀”。你想想人的记忆是怎么工作的——昨天中午吃了什么你可能已经忘了，但你知道自己不吃香菜、对海鲜过敏。前者是流水，后者是沉淀。Clawdbot的两层架构完美复刻了这个模式。Daily Notes负责记流水，MEMORY.md负责存沉淀，两者职责清晰不混淆。而且它用Markdown存储这个选择也很有讲究——**人能直接打开看、能手动编辑、能用git做版本管理**，不像向量数据库那样是个黑盒。我之前踩过一个坑，用某个Agent框架做项目，它的记忆存在向量库里，某天发现Agent的行为突然变得很奇怪，查了半天发现是记忆里存了一条错误信息，但我想删都不知道怎么删，因为那玩意儿不是给人看的。Clawdbot就没这个问题，记忆出了问题你直接打开md文件改就完了。

第二个值得学的是它的插件和Skills系统设计。现在做AI Agent的一个普遍思路是”大而全”——恨不得把所有功能都内置进去，发邮件、订会议、查天气、控制智能家居、写代码……功能列表能写两页纸。这种思路的问题是什么？维护成本高得离谱。每个功能都得有人维护，API变了得跟着改，用户的需求千奇百怪你根本满足不完。更要命的是，功能越多bug越多，改一个地方可能影响另一个地方，整个系统会变得越来越脆弱。

Clawdbot走的是完全相反的路：核心系统只做最基础的事情——消息路由、模型调用、上下文管理、安全沙箱。其他所有功能都通过插件和Skills来实现。它现在社区里有273个Skills，覆盖各种场景，但这些都不是官方维护的，是社区贡献的。官方只维护核心的9个，其他264个爱用不用、出了问题社区自己修。**这种”核心精简、外围开放”的架构模式，才是做平台型产品的正确姿势。**你看成功的产品——VS Code、Obsidian、Raycast——哪个不是这个思路？核心团队专注做好底层，生态靠社区来搞。

而且它的Skills系统设计得特别工程化。每个Skill就是一个标准格式的配置文件加一个执行脚本，有manifest描述元信息，有input/output schema定义接口，有sandbox配置指定权限边界。你要写一个新Skill，照着模板填就完了，不需要理解整个系统是怎么跑的。我自己照着写过几个，大概一两个小时就能搞定一个可用的Skill。这种低门槛是生态繁荣的前提，你让开发者读三天文档才能写个插件，没人愿意来玩的。

第三个让我印象深刻的是它的安全沙箱机制。AI Agent和普通chatbot最大的区别是什么？是它能执行真实操作——跑命令、改文件、发请求、调API。这个能力是双刃剑，用好了能帮你干活，用不好能把你的数据删光、把你的密码发出去。去年不是有个新闻吗，某个AI Agent平台上的应用被曝出数据泄露，原因就是AI生成的代码有漏洞，把用户数据往不该发的地方发。还有更离谱的，有个Agent为了”修复”bug直接把数据库删了。这些事情听起来像段子，但都是真实发生的。**只要Agent能执行代码，这类风险就永远存在。问题是怎么降低风险、怎么控制爆炸半径。**

Clawdbot在这块下了很大功夫。它有一套完整的sandbox机制：默认情况下Agent执行任何敏感操作都需要用户确认，文件操作只能在指定目录里搞，网络请求有白名单限制，系统命令要过审批。Docker部署的话更狠——非root用户运行、文件系统可以设成只读、capabilities全部drop掉。它还有个openclaw security audit --deep命令，能扫描当前配置有没有安全隐患，扫完给你出报告告诉你哪里有风险、怎么修。我见过太多Agent项目在安全这块糊弄，觉得”反正是自己用又不是生产环境”，结果真出事了才后悔。Clawdbot把这些东西做成了默认配置和标准工具，你不用是安全专家也能把基本面做好，这个思路太对了。

有个细节我特别想提一下。Clawdbot的安全策略明确写了”prompt injection attacks are out of scope”——就是说它不试图防prompt注入，因为以现在的技术这玩意防不住。这种诚实我觉得比那些吹”100%安全”的产品靠谱多了。**它的思路是：既然prompt注入防不住，那就假设Agent会被”骗”，然后在执行层面做限制，让Agent就算被骗了也干不了太出格的事。**这是一种务实的工程思维，不追求理论上的完美，而是在现有约束下做到实际可行的最好。

再说说它的多平台架构。Clawdbot支持WhatsApp、Telegram、Discord、Slack、iMessage、Signal、Teams……基本上你能想到的聊天平台它都支持。这事儿听起来简单，不就是接个API吗？但真正做过的人都知道有多坑。每个平台的消息格式不一样、富文本能力不一样、附件限制不一样、webhook机制不一样、rate limit不一样。你要是每个平台单独写一套逻辑，代码会变成一坨屎，改一个功能得改八遍，bug改不完。

Clawdbot的做法是搞了一个WebSocket Gateway作为中心枢纽，所有平台的消息都先转成统一的内部格式进Gateway，处理完再转成各平台的格式出去。中间的AI Agent根本不知道消息是从哪个平台来的，它只处理标准格式的输入输出。**这就是经典的适配器模式，但它实现得特别干净**。每个平台对应一个Channel Adapter，Adapter只负责格式转换这一件事，业务逻辑一行都没有。你要加一个新平台，就写一个新Adapter，不用动任何现有代码。我照着这个思路重构过自己的一个多平台机器人项目，代码量直接砍了一半，而且之后加新平台变得特别轻松。

还有个我觉得被严重低估的设计：它的CLI系统。Clawdbot有100多个CLI子命令，能干的事情包括但不限于：管理Skills、配置插件、调试Agent、查看日志、管理记忆、做安全审计、导入导出数据。为什么这很重要？因为**CLI是最被低估的用户体验**。做产品的人总喜欢搞花里胡哨的Web界面，觉得命令行”不友好”。但对开发者用户来说，能用命令行搞定的事情就别让我点鼠标。Clawdbot的目标用户是技术人群，它就老老实实把CLI做好，而不是硬塞一个半吊子的Web UI。每个命令都有详细的help，常用操作都有快捷方式，输出格式支持JSON方便脚本处理。这才是懂用户的产品。

最后说点个人感受。我研究Clawdbot最大的收获不是学会了什么具体技术，而是看到了一种做产品的态度：**不追求功能多，追求每个功能都做对；不追求大而全，追求核心足够稳；不追求理论完美，追求工程可行。**现在太多AI创业公司的思路是堆功能、卷参数、比谁的Agent能做的事情多。但Clawdbot证明了另一条路是可行的——把基础设施做扎实，把架构设计清楚，把扩展性留好，剩下的让社区来补。

它也不是没有问题。比如文档写得一般，新手上手曲线有点陡；比如有些高级功能藏得很深，不翻源码找不到；比如社区Skills质量参差不齐，有些根本跑不起来。但瑕不掩瑜，作为一个开源项目，它在架构设计上展现出来的成熟度，确实是很多拿了融资的创业公司都比不了的。

如果你在做AI Agent相关的东西，我真心建议花点时间把Clawdbot的代码过一遍。不是说要照搬它的实现，而是去理解它为什么这么设计、它踩过哪些坑、它怎么在各种约束下做取舍。这些东西比学会用某个框架的API有价值多了。

有问题可以评论区聊，我尽量回复。
